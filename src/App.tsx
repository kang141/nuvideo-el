// SPDX-License-Identifier: AGPL-3.0-or-later
import { useState, useEffect, useRef, useCallback } from "react";
import { EditorPage } from "./components/EditorPage";
import { RecordingStatusBar } from "./components/RecordingStatusBar";
import { HomePage } from "./components/HomePage";
import { AppState, RecordingState, RenderGraph, MouseEvent } from "./types";
import { mouseTracker } from "./recorder";
import { nativeAudioRecorder } from "./recorder/audio-capture";
import { webcamRecorder } from "./recorder/webcam-capture";
import { cn } from "@/lib/utils";
import { Language } from "./i18n/translations";
import { motion, AnimatePresence } from "framer-motion";

function App() {
  const [appState, setAppState] = useState<AppState>("home");

  const [recordingState, setRecordingState] = useState<RecordingState>(() => ({
    isRecording: false,
    duration: 0,
    isPaused: false,
    format: "video",
    autoZoom: localStorage.getItem("nuvideo_auto_zoom_enabled") !== "false",
  }));
  const [renderGraph, setRenderGraph] = useState<RenderGraph | null>(null);
  const lastVideoUrlRef = useRef<string | null>(null);
  const audioDelayRef = useRef<number>(0);
  const webcamDelayRef = useRef<number>(0);
  const readyOffsetRef = useRef<number>(0);

  const [autoZoomEnabled, setAutoZoomEnabled] = useState(
    () => localStorage.getItem("nuvideo_auto_zoom_enabled") !== "false",
  );

  const handleUpdateAutoZoom = (val: boolean) => {
    setAutoZoomEnabled(val);
    localStorage.setItem("nuvideo_auto_zoom_enabled", val.toString());
  };

  const [language, setLanguage] = useState<Language>(
    () => (localStorage.getItem("nuvideo_language") as Language) || "zh",
  );

  const handleUpdateLanguage = (lang: Language) => {
    setLanguage(lang);
    localStorage.setItem("nuvideo_language", lang);
  };

  const transitionTo = useCallback((nextState: AppState) => {
    // Á´ãÂç≥ÈÄöÁü• UI ËøõÂÖ•ÂàáÊç¢Áä∂ÊÄÅ
    setAppState(nextState);
  }, []);

  useEffect(() => {
    document.documentElement.classList.add("dark");
    return () => document.documentElement.classList.remove("dark");
  }, []);

  useEffect(() => {
    const ipc = (window as any).ipcRenderer;
    if (!ipc) return;

    // ÈíàÂØπÂΩïÂà∂Ê®°ÂºèÂÅöÊûÅÈÄüÂ§ÑÁêÜ
    const delay = appState === "recording" ? 80 : 150;

    // Áº©Áü≠Âª∂ËøüÔºåÁ°Æ‰øù Resize ÂèëÁîüÂú® AnimatePresence ÁöÑ Exit ‰πãÂêéÔºåEnter ‰πãÂâç
    const timeout = setTimeout(() => {
      if (appState === "home") {
        ipc.send("resize-window", { width: 720, height: 480, resizable: true });
      } else if (appState === "editor") {
        ipc.send("resize-window", {
          width: 1200,
          height: 800,
          resizable: true,
        });
      } else if (appState === "recording") {
        // ÂÖ≥ÈîÆÔºöÂÖàËÆ©ËÉåÊôØÈÄèÊòéÔºåÂÜçÁº©Êîæ
        ipc.send("resize-window", {
          width: 520,
          height: 84, // ‰ªé 72 Â¢ûÂä†Âà∞ 84Ôºå‰∏∫Èò¥ÂΩ±ÁïôÂá∫Á©∫Èó¥
          resizable: false,
          position: "bottom",
          mode: "recording",
        });
      }
    }, delay); // 150ms ÊòØ exit Âä®ÁîªËøõË°åÂà∞‰∏ÄÂçäÁöÑÊó∂Èó¥ÔºåÊ≠§Êó∂Á™óÂè£ÈÄèÊòéÂ∫¶ÊûÅ‰ΩéÔºåÂæÆË∞ÉÂ∞∫ÂØ∏ÊúÄ‰∏çÊòìÂØüËßâ

    return () => clearTimeout(timeout);
  }, [appState]);

  useEffect(() => {
    if (!recordingState.isRecording || recordingState.isPaused) {
      return;
    }

    const interval = setInterval(() => {
      setRecordingState((prev) => {
        const nextDuration = prev.duration + 100;

        if (prev.format === "gif" && nextDuration >= 15000) {
          console.log(
            "[App] GIF recording limit reached (15s), stopping automatically",
          );
          handleStopRecording();
          return {
            ...prev,
            duration: 15000,
            isRecording: false,
          };
        }

        return {
          ...prev,
          duration: nextDuration,
        };
      });
    }, 100);

    return () => clearInterval(interval);
  }, [recordingState.isRecording, recordingState.isPaused]);

  const [isStopping, setIsStopping] = useState(false);

  const handleStartRecording = useCallback(async (
    sourceId: string,
    format: "video" | "gif" = "video",
    autoZoom: boolean = true,
    audioConfig: {
      microphoneId: string | null;
      microphoneLabel: string | null;
      systemAudio: boolean;
    },
    webcamConfig: {
      enabled: boolean;
      deviceId: string | null;
    },
  ) => {
    try {
      console.log("[App] Starting FFmpeg recording...");
      await mouseTracker.syncClock();
      (window as any).ipcRenderer.send('start-mouse-monitoring');
      
      // 1. ÂêØÂä® FFmpeg Sidecar ÂΩïÂà∂
      const startResult = await (window as any).ipcRenderer.invoke('start-sidecar-record', sourceId);
      
      if (!startResult?.success || !startResult?.bounds || !startResult?.sessionId) {
         throw new Error(startResult?.error || "Failed to start recording.");
      }

      // 2. Ê≥®ÂÜå‰ºöËØù
      await (window as any).ipcRenderer.invoke('register-session', { 
        sessionId: startResult.sessionId 
      });

      // 3. Âü∫‰∫éËßÜÈ¢ëËæπÁïåÂêØÂä®Èº†Ê†áËøΩË∏™ÂíåÈü≥È¢ë/ÊëÑÂÉèÂ§¥
      mouseTracker.start(startResult.bounds);
      mouseTracker.align(startResult.t0);

      const [audioT0, webcamT0] = await Promise.all([
        nativeAudioRecorder.start(sourceId, audioConfig),
        webcamConfig.enabled && webcamConfig.deviceId
          ? webcamRecorder.start(webcamConfig.deviceId)
          : Promise.resolve(0),
      ]);

      readyOffsetRef.current = startResult.readyOffset;
      audioDelayRef.current = (audioT0 || performance.now()) - startResult.t0 + 150;
      webcamDelayRef.current = webcamT0 > 0 ? webcamT0 - startResult.t0 : 0;

      setRecordingState({
        isRecording: true,
        startTime: Date.now(),
        duration: 0,
        isPaused: false,
        format,
        autoZoom,
      });

      transitionTo("recording");
    } catch (err) {
      console.error("Failed to start recording:", err);
      setRecordingState((prev) => ({ ...prev, isRecording: false }));
      alert("ÂΩïÂà∂ÂêØÂä®Â§±Ë¥•: " + (err as Error).message);
    }
  }, [transitionTo]);

  // fetchSessionEvents Â∑≤Â∫üÂºÉ - WebCodecs ÊñπÊ°àÁõ¥Êé•‰ªé mouseTracker Ëé∑Âèñ‰∫ã‰ª∂

  const handleStopRecording = async () => {
    if (!recordingState.isRecording) return;

    setIsStopping(true);
    try {
      // ÂÖ≥ÈîÆ‰øÆÂ§çÔºöÁ´ãÂç≥Ê†áËÆ∞ÂÅúÊ≠¢ÂΩïÂà∂ÔºåÈò≤Ê≠¢ËÆ°Êó∂Âô®ÁªßÁª≠Á¥ØÂä†
      setRecordingState((prev) => ({
        ...prev,
        isRecording: false,
        duration: 0,
        isPaused: false,
      }));

      // üéØ ÂÖ≥ÈîÆ‰øÆÂ§ç:ÂÖàÂÅúÊ≠¢Èº†Ê†áËøΩË∏™Âπ∂Ëé∑Âèñ‰∫ã‰ª∂Êï∞ÁªÑ
      const mouseEvents = mouseTracker.stop();
      console.log("[App] Stopping all recording streams...");

      // üéØ ÊûÅËá¥‰ºòÂåñ:Âπ∂ÂèëÂÅúÊ≠¢ÊâÄÊúâÊµÅ
      const [sessionResult, audioBuffers, webcamBuffer] = await Promise.all([
        (window as any).ipcRenderer.invoke('stop-sidecar-record'),
        nativeAudioRecorder.stop(),
        webcamRecorder.stop(),
      ]);

      console.log("[App] All streams stopped synchronously");

      if (!sessionResult?.success) {
        throw new Error("Failed to stop recording");
      }

      const { sessionId } = sessionResult;

      // Â¶ÇÊûúÊúâÂΩïÂà∂Âà∞Èü≥È¢ëÔºå‰øùÂ≠òÂà∞‰ºöËØùÁõÆÂΩï (ÂàÜËΩ®Ê®°Âºè)
      const audioTracks: any[] = [];
      if (audioBuffers && (audioBuffers.micBuffer || audioBuffers.sysBuffer)) {
        const audioSaveResult = await (window as any).ipcRenderer.invoke(
          "save-session-audio-segments",
          {
            sessionId,
            micBuffer: audioBuffers.micBuffer,
            sysBuffer: audioBuffers.sysBuffer,
          },
        );

        if (audioSaveResult.success) {
          if (audioSaveResult.micPath) {
            audioTracks.push({
              source: "microphone",
              startTime: 0,
              path: `nuvideo://session/${sessionId}/audio_mic.webm`,
              volume: 1.0,
              fadeIn: 300,
              fadeOut: 300,
            });
          }
          if (audioSaveResult.sysPath) {
            audioTracks.push({
              source: "system",
              startTime: 0,
              path: `nuvideo://session/${sessionId}/audio_sys.webm`,
              volume: 1.0,
              fadeIn: 300,
              fadeOut: 300,
            });
          }
        }
      }

      // Â§ÑÁêÜÊëÑÂÉèÂ§¥ËßÜÈ¢ë‰øùÂ≠ò
      let finalWebcamPath = undefined;
      if (webcamBuffer && webcamBuffer.byteLength > 0) {
        const webcamSaveResult = await (window as any).ipcRenderer.invoke(
          "save-session-webcam",
          {
            sessionId,
            arrayBuffer: webcamBuffer,
          },
        );
        if (webcamSaveResult.success) {
          finalWebcamPath = `nuvideo://session/${sessionId}/webcam.mp4`;
        }
      }
      
      // üéØ ÂÖ≥ÈîÆ‰øÆÂ§ç:‰øùÂ≠òÈº†Ê†á‰∫ã‰ª∂Âà∞Êñá‰ª∂Á≥ªÁªü
      await (window as any).ipcRenderer.invoke('save-session-events', {
        sessionId,
        events: mouseEvents
      });
      console.log(`[App] Saved ${mouseEvents.length} mouse events to session`);
      
      const tailPaddingMs = 150;
      const lastEventT = mouseEvents.length > 0 ? mouseEvents[mouseEvents.length - 1].t : 0;
      const finalDurationMs = Math.max(
        recordingState.duration,
        Math.ceil(lastEventT + tailPaddingMs),
      );

      const finalGraph: RenderGraph = {
        videoSource: `nuvideo://session/${sessionId}/video_raw.mp4`,
        duration: finalDurationMs,
        audio: { tracks: audioTracks },
        webcamSource: finalWebcamPath,
        webcamDelay: webcamDelayRef.current,
        mouse: mouseEvents,
        mouseTheme: {
          style: "macOS",
          size: 48,
          showRipple: true,
          rippleColor: "#ffffff",
          showHighlight: false,
          highlightColor: "rgba(255,255,255,0.2)",
        },
        mousePhysics: { smoothing: 0.88, speedLimit: 2400 },
        camera: {
          intents: [],
          algorithm: "spring",
          springConfig: { stiffness: 28, damping: 18 },
        },
        config: {
          fps: 60,
          ratio: "16:9",
          outputWidth: 1920,
          targetFormat: recordingState.format,
        },
        autoZoom: recordingState.autoZoom,
        webcam: { isEnabled: !!finalWebcamPath },
        audioDelay: audioDelayRef.current,
      };

      setRecordingState((prev) => ({
        ...prev,
        isRecording: false,
        duration: 0,
        isPaused: false,
      }));
      setRenderGraph(finalGraph);
      transitionTo("editor");
    } catch (err) {
      console.error("[App] Stop recording failed:", err);
      alert("ÂÅúÊ≠¢ÂΩïÂà∂Â§±Ë¥•: " + (err as Error).message);
      transitionTo("home");
    } finally {
      setIsStopping(false);
      (window as any).ipcRenderer.send('stop-mouse-monitoring');
    }
  };

  useEffect(() => {
    const ipc = (window as any).ipcRenderer;
    if (!ipc) return;

    // ÂΩªÂ∫ïÊäõÂºÉÂä®ÁîªÔºåResize Âá†‰πéÁ´ãÂç≥Ëß¶ÂèëÔºå‰∏é React Ê∏≤ÊüìÂêåÊ≠•
    const timeout = setTimeout(() => {
      if (appState === "home") {
        ipc.send("resize-window", { width: 720, height: 480, resizable: true });
        ipc.send('set-ignore-mouse-events', false); // ÂÖ≥ÈîÆÔºöÊÅ¢Â§çÈ¶ñÈ°µÁöÑ‰∫§‰∫íÊÄß
      } else if (appState === "editor") {
        ipc.send("resize-window", {
          width: 1200,
          height: 800,
          resizable: true,
        });
        ipc.send('set-ignore-mouse-events', false); // ÂÖ≥ÈîÆÔºöÊÅ¢Â§çÁºñËæëÂô®ÁöÑ‰∫§‰∫íÊÄß
      } else if (appState === "recording") {
        ipc.send("resize-window", {
          width: 520,
          height: 84,
          resizable: false,
          position: "bottom",
          mode: "recording",
        });
      }
    }, 0);

    return () => clearTimeout(timeout);
  }, [appState]);

  const handlePauseRecording = () => {
    setRecordingState((prev) => ({ ...prev, isPaused: true }));
  };

  const handleResumeRecording = () => {
    setRecordingState((prev) => ({ ...prev, isPaused: false }));
  };

  const handleBackToHome = () => {
    transitionTo("home");
    setRenderGraph(null);
  };

  useEffect(() => {
    if (renderGraph?.videoSource) {
      if (
        lastVideoUrlRef.current &&
        lastVideoUrlRef.current !== renderGraph.videoSource
      ) {
        URL.revokeObjectURL(lastVideoUrlRef.current);
      }
      lastVideoUrlRef.current = renderGraph.videoSource;
    }
    return () => {
      if (lastVideoUrlRef.current) {
        URL.revokeObjectURL(lastVideoUrlRef.current);
        lastVideoUrlRef.current = null;
      }
    };
  }, [renderGraph?.videoSource]);

  return (
    <div
      className={cn(
        "relative flex h-screen w-screen flex-col overflow-hidden font-sans",
        appState === "home" ? "mesh-gradient" : "",
        appState === "recording"
          ? "bg-transparent border-0 shadow-none"
          : "bg-neutral-950 rounded-[24px] border border-white/[0.08] shadow-[0_32px_128px_-16px_rgba(0,0,0,0.8)]"
      )}
    >
      <div 
        style={{ willChange: 'transform, filter' }}
        className={cn(
          "flex h-full w-full flex-col relative z-10 transition-[filter,transform,opacity] duration-500 ease-out-expo"
        )} 
        key={language}
      >
        <AnimatePresence mode="wait">
        {/* 1. ÂΩïÂà∂Ê®°Âºè */}
          {appState === "recording" && (
            <motion.div 
              key="recording"
              initial={{ opacity: 0, scale: 0.9, y: 20 }}
              animate={{ opacity: 1, scale: 1, y: 0 }}
              exit={{ opacity: 0, scale: 0.9, y: 20 }}
              className="flex h-full w-full items-center justify-center"
            >
              <RecordingStatusBar
                duration={recordingState.duration}
                isPaused={recordingState.isPaused}
                onStop={handleStopRecording}
                onPause={handlePauseRecording}
                onResume={handleResumeRecording}
                language={language}
                isStopping={isStopping}
              />
            </motion.div>
          )}

          {/* 2. È¶ñÈ°µ */}
          {appState === "home" && (
            <motion.div 
              key="home"
              initial={{ opacity: 0, y: 10 }}
              animate={{ opacity: 1, y: 0 }}
              exit={{ opacity: 0, scale: 0.95, filter: 'blur(10px)' }}
              transition={{ duration: 0.5, ease: [0.16, 1, 0.3, 1] }}
              className="h-full w-full"
            >
              <HomePage
                onStartRecording={handleStartRecording}
                autoZoomEnabled={autoZoomEnabled}
                onToggleAutoZoom={handleUpdateAutoZoom}
                language={language}
                setLanguage={handleUpdateLanguage}
              />
            </motion.div>
          )}

          {/* 3. ÁºñËæëÂô® */}
          {appState === "editor" && (
            <motion.div 
              key="editor"
              initial={{ opacity: 0, x: 20 }}
              animate={{ opacity: 1, x: 0 }}
              exit={{ opacity: 0, x: -20 }}
              className="h-full w-full"
            >
              <EditorPage
                renderGraph={renderGraph}
                onBack={handleBackToHome}
                language={language}
                setLanguage={handleUpdateLanguage}
                autoZoomEnabled={autoZoomEnabled}
                onToggleAutoZoom={handleUpdateAutoZoom}
              />
            </motion.div>
          )}
        </AnimatePresence>
      </div>

    </div>
  );
}

export default App;
