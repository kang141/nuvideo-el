import { useState, RefObject, useRef } from 'react';
import { Muxer, StreamTarget } from 'mp4-muxer';
import { QualityConfig } from '../../constants/quality';
import { RenderGraph } from '../../types/render-graph';
import { enableIncrementalMode, resetCameraCache } from '../../core/camera-solver';
import { applyRenderConfig, EXPORT_CONFIG, PREVIEW_CONFIG } from '../../core/render-config';

interface UseVideoExportOptions {
  videoRef: RefObject<HTMLVideoElement>;
  canvasRef: RefObject<HTMLCanvasElement>;
  maxDuration: number;
  exportDuration?: number;
  onSeek: (time: number) => void;
  setIsPlaying: (playing: boolean) => void;
  renderFrame: (timestampMs: number) => void | Promise<void>;
  isExporting: boolean;
  setIsExporting: (v: boolean) => void;
  renderGraph?: RenderGraph;
}

const ENCODER_QUEUE_THRESHOLD = 12;
const PROGRESS_THROTTLE_MS = 100;

export function useVideoExport({
  videoRef,
  canvasRef,
  maxDuration,
  exportDuration,
  onSeek: _onSeek,
  setIsPlaying,
  renderFrame,
  isExporting: _isExporting,
  setIsExporting,
  renderGraph,
}: UseVideoExportOptions) {
  const [exportProgress, setExportProgress] = useState(0);
  const isExportingRef = useRef(false);
  const LAST_DIR_KEY = 'nuvideo_last_export_dir';
  
  type RendererIPC = { invoke: (channel: string, payload?: unknown) => Promise<unknown> };
  const ipc = ((window as unknown) as { ipcRenderer?: RendererIPC }).ipcRenderer!;

  const cancelExport = () => {
    isExportingRef.current = false;
    setIsExporting(false);
    resetCameraCache();
  };

  const handleExport = async (quality?: QualityConfig, targetPath?: string | null): Promise<{ success: boolean; filePath?: string }> => {
    console.log('[useVideoExport] handleExport called', { 
      quality, 
      targetPath, 
      hasRenderGraph: !!renderGraph,
      audioTracks: renderGraph?.audio?.tracks?.length,
      videoSource: renderGraph?.videoSource 
    });
    if (renderGraph) {
      console.log('[useVideoExport] RenderGraph details:', JSON.stringify(renderGraph, (k,v) => k === 'mouse' ? undefined : v, 2));
    }

    if (isExportingRef.current) return { success: false };
    const video = videoRef.current;
    const canvas = canvasRef.current;
    if (!video || !canvas) {
      console.error('[useVideoExport] Required DOM elements missing:', { video: !!video, canvas: !!canvas });
      return { success: false };
    }
    
    // ğŸ¯ å…³é”®ä¿®å¤ï¼šå¯¼å‡ºå‰åº”ç”¨ç»Ÿä¸€çš„æ¸²æŸ“é…ç½®
    console.log('[å¯¼å‡º] åº”ç”¨å¯¼å‡ºæ¸²æŸ“é…ç½®...');
    console.log('[å¯¼å‡º] ç”»å¸ƒå½“å‰å°ºå¯¸:', { 
      width: canvas.width, 
      height: canvas.height,
      style: { width: canvas.style.width, height: canvas.style.height }
    });
    
    applyRenderConfig(canvas, EXPORT_CONFIG);
    
    console.log('[å¯¼å‡º] é…ç½®åº”ç”¨åç”»å¸ƒå°ºå¯¸:', { 
      width: canvas.width, 
      height: canvas.height,
      logicalWidth: EXPORT_CONFIG.canvasWidth,
      logicalHeight: EXPORT_CONFIG.canvasHeight,
      dpr: EXPORT_CONFIG.dpr
    });
    
    let streamId: string | null = null;
    let isGif = quality?.id === 'gif' || targetPath?.toLowerCase().endsWith('.gif');
    const bitrate = isGif ? 150 * 1024 * 1024 : (quality?.bitrate || 50 * 1024 * 1024);
    const fps = 60;
    const durationSeconds = exportDuration ?? maxDuration;
    // ç¨³å®šæ€§åŠ å›ºï¼šå¼ºåˆ¶åˆ†è¾¨ç‡ä¸ºå¶æ•°ä»¥é€‚é…ç¡¬ä»¶ç¼–ç å™¨
    // ä½¿ç”¨é€»è¾‘å°ºå¯¸ï¼ˆEXPORT_CONFIG å·²ç»å¤„ç†äº† DPRï¼‰
    const width = EXPORT_CONFIG.canvasWidth % 2 === 0 ? EXPORT_CONFIG.canvasWidth : EXPORT_CONFIG.canvasWidth - 1;
    const height = EXPORT_CONFIG.canvasHeight % 2 === 0 ? EXPORT_CONFIG.canvasHeight : EXPORT_CONFIG.canvasHeight - 1;
    
    console.log('[å¯¼å‡º] ç¼–ç å™¨å°ºå¯¸:', { width, height, dpr: EXPORT_CONFIG.dpr });
    console.log('[å¯¼å‡º] è§†é¢‘å‚æ•°:', { fps, bitrate, durationSeconds, isGif });

    // åœ¨ try ä¹‹å‰å£°æ˜ç¼–ç å™¨å˜é‡ï¼Œä»¥ä¾¿åœ¨é”™è¯¯å¤„ç†ä¸­å¯ä»¥è®¿é—®å®ƒä»¬
    let videoEncoder: VideoEncoder | undefined = undefined;
    let audioEncoder: AudioEncoder | null = null;

    try {
      isExportingRef.current = true;
      setIsExporting(true);
      setExportProgress(0);

      // 1. ç¡®å®šä¿å­˜è·¯å¾„
      let finalPath = targetPath;
      if (!finalPath) {
        const ext = isGif ? '.gif' : '.mp4';
        const suggestName = `nuvideo_export_${Date.now()}${ext}`;
        const saveResult = await ipc.invoke('show-save-dialog', { defaultName: suggestName }) as { canceled: boolean; filePath?: string };
        if (saveResult.canceled || !saveResult.filePath) throw new Error('CanceledByUser');
        finalPath = saveResult.filePath;
        const lastSlashIndex = Math.max(finalPath.lastIndexOf('/'), finalPath.lastIndexOf('\\'));
        if (lastSlashIndex > -1) {
          const dir = finalPath.substring(0, lastSlashIndex);
          localStorage.setItem(LAST_DIR_KEY, dir);
        }
      }

      isGif = finalPath!.toLowerCase().endsWith('.gif');
      const workPath = isGif ? finalPath!.replace(/\.(gif|mp4)$/i, '') + `.temp_${Date.now()}.mp4` : finalPath!;

      // 2. é¢„è§£ç å¹¶æ··åˆéŸ³è½¨ï¼ˆGIFæ¨¡å¼è·³è¿‡éŸ³é¢‘å¤„ç†ï¼‰
      let decodedAudio: AudioBuffer | null = null;
      console.log('[useVideoExport] Entering audio processing block...');
      
      if (renderGraph?.audio?.tracks && !isGif) {
        try {
          const audioCtx = new AudioContext({ sampleRate: 48000 });
          const totalSamples = Math.ceil(durationSeconds * 48000);
          const mixedBuffer = audioCtx.createBuffer(2, totalSamples, 48000);
          
          let hasAnyAudio = false;
          const tracks = renderGraph.audio.tracks;
          console.log('[useVideoExport] Audio mixing start. Track count:', tracks.length, 'Duration:', durationSeconds);

          if (tracks.length === 0) {
            console.warn('[useVideoExport] Audio track list is EMPTY.');
          }

          for (const track of tracks) {
            const trackPath = track.path || track.filePath;
            if (!trackPath) {
              console.warn('[useVideoExport] Track missing path:', track);
              continue;
            }

            const targetUrl = trackPath;
            console.log(`[useVideoExport] Processing track: ${track.source}, URL: ${targetUrl}`);
            
            try {
              const resp = await fetch(targetUrl);
              if (!resp.ok) {
                console.error(`[useVideoExport] Fetch failed for ${track.source}: ${resp.status} ${resp.statusText}`);
                continue;
              }
              const arrayBuffer = await resp.arrayBuffer();
              console.log(`[useVideoExport] Decoded raw size: ${arrayBuffer.byteLength} bytes`);
              
              const trackBuffer = await audioCtx.decodeAudioData(arrayBuffer);
              console.log(`[useVideoExport] Track decoded: ${track.source}, Duration: ${trackBuffer.duration.toFixed(2)}s, Channels: ${trackBuffer.numberOfChannels}`);
              
              // æ··åˆåˆ° mixedBuffer
              const startOffset = Math.max(0, Math.floor(((track.startTime || 0) + (renderGraph.audioDelay || 0)) / 1000 * 48000));
              const vol = track.volume ?? 1.0;
              console.log(`[useVideoExport] Mixing ${track.source} at offset: ${startOffset}, volume: ${vol}`);
              
              for (let channel = 0; channel < Math.min(mixedBuffer.numberOfChannels, trackBuffer.numberOfChannels); channel++) {
                const targetData = mixedBuffer.getChannelData(channel);
                const sourceData = trackBuffer.getChannelData(channel);
                const copyLen = Math.min(sourceData.length, targetData.length - startOffset);
                
                // æ·»åŠ è¾¹ç•Œæ£€æŸ¥ï¼Œé˜²æ­¢æ•°ç»„è¶Šç•Œ
                for (let i = 0; i < copyLen; i++) {
                  const targetIdx = startOffset + i;
                  if (targetIdx >= 0 && targetIdx < targetData.length) {
                    targetData[targetIdx] += sourceData[i] * vol;
                  }
                }
              }
              hasAnyAudio = true;
            } catch (trackErr) {
              console.error(`[useVideoExport] Critical error mixing track ${track.source}:`, trackErr);
            }
          }
          
          if (hasAnyAudio) {
            let maxAmp = 0;
            const testData = mixedBuffer.getChannelData(0);
            for (let i = 0; i < Math.min(testData.length, 100000); i += 100) {
              maxAmp = Math.max(maxAmp, Math.abs(testData[i]));
            }
            console.log(`[useVideoExport] Audio mixing complete. Max amplitude sample: ${maxAmp.toFixed(4)}`);
            decodedAudio = mixedBuffer;
          } else {
            console.warn('[useVideoExport] No audio tracks were successfully processed.');
          }
        } catch (e) {
          console.error('[useVideoExport] Audio mixing crash:', e);
        }
      } else {
        console.warn('[useVideoExport] renderGraph.audio or .tracks is missing!');
      }

      // 3. å‡†å¤‡ç¼–ç å™¨æ¢æµ‹
      const codecCandidates = isGif 
        ? ['vp09.00.10.08'] 
        : [
            'avc1.640033', // High Profile, Level 5.1 (æ”¯æŒ 4K)
            'avc1.4d0033', // Main Profile, Level 5.1 (æ”¯æŒ 4K)
            'avc1.42E034', // Baseline Profile, Level 5.2 (æé«˜å…¼å®¹æ€§ï¼Œä¸”æ”¯æŒè¶…å¤§åˆ†è¾¨ç‡)
          ];
      
      let videoConfig: VideoEncoderConfig | null = null;
      for (const codec of codecCandidates) {
        const testConfig: VideoEncoderConfig = { 
          codec, width, height, bitrate, framerate: fps, 
          hardwareAcceleration: 'prefer-hardware' 
        };
        try {
          const support = await VideoEncoder.isConfigSupported(testConfig);
          if (support.supported) {
            videoConfig = testConfig;
            console.log('[useVideoExport] Selected codec:', codec);
            break;
          }
        } catch (err) {
          console.warn(`[useVideoExport] Codec ${codec} not supported:`, err);
        }
      }
      
      if (!videoConfig) {
        // é¢å¤–å°è¯•åŸºæœ¬é…ç½®ï¼Œç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªå¯ç”¨çš„ç¼–ç å™¨
        try {
          // å°è¯•ä½¿ç”¨åŸºæœ¬çš„VP8ç¼–ç å™¨ï¼ˆé€šå¸¸åœ¨å¤§å¤šæ•°ç³»ç»Ÿä¸Šå¯ç”¨ï¼‰
          const basicConfig: VideoEncoderConfig = { 
            codec: 'vp8', width, height, bitrate, framerate: fps, 
            hardwareAcceleration: 'prefer-software' 
          };
          const basicSupport = await VideoEncoder.isConfigSupported(basicConfig);
          if (basicSupport.supported) {
            videoConfig = basicConfig;
            console.log('[useVideoExport] Selected fallback codec: vp8');
          }
        } catch (err) {
          console.warn('[useVideoExport] Basic VP8 codec not supported:', err);
        }
        
        // å¦‚æœä»ç„¶æ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„é…ç½®ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
        if (!videoConfig) {
          videoConfig = { 
            codec: isGif ? 'vp09.00.10.08' : 'avc1.42E034', 
            width, height, bitrate, framerate: fps, 
            hardwareAcceleration: 'prefer-software' 
          };
        }
      }

      // 4. æ‰“å¼€æµä¸ Muxer
      const openResult = await ipc.invoke('open-export-stream', { targetPath: workPath }) as { success: boolean; streamId?: string; error?: string };
      if (!openResult.success) throw new Error(`StreamOpenFailed: ${openResult.error}`);
      streamId = openResult.streamId || null;

      let writeChain = Promise.resolve();
      let chunksReceived = 0;
      let lastWriteLog = 0;

      const muxerTarget = new StreamTarget({
        onData: (chunk, position) => {
          const chunkLen = chunk.length;
          writeChain = writeChain.then(() => 
            ipc.invoke('write-export-chunk', { streamId, chunk, position })
          ).then(() => { 
            chunksReceived++;
            if (typeof position !== 'number') {
              if (performance.now() - lastWriteLog > 1000) {
                console.log(`[useVideoExport] Writing... Total chunks: ${chunksReceived}, last size: ${chunkLen}`);
                lastWriteLog = performance.now();
              }
            } else {
              console.log(`[useVideoExport] Header backfill at: ${position}, size: ${chunkLen}`);
            }
          }).catch(err => console.error('[useVideoExport] Write Error:', err));
        }
      });

      const muxer = new Muxer({
        target: muxerTarget as any,
        video: { codec: (videoConfig.codec.startsWith('vp') ? 'vp9' : 'avc') as any, width, height, frameRate: fps },
        audio: decodedAudio && !isGif ? { codec: 'aac', sampleRate: 48000, numberOfChannels: 2 } : undefined,
        fastStart: 'in-memory', // æ”¹ä¸ºå†…å­˜ç¼“å†²æ¨¡å¼ï¼Œå¯¹äºçŸ­è§†é¢‘ï¼ˆæ•°åˆ†é’Ÿå†…ï¼‰æ¥è¯´æ›´ç¨³å®šï¼Œé¿å…å›å¡«å¤±è´¥
        firstTimestampBehavior: 'offset',
      });
      console.log('[useVideoExport] Muxer initialized with fastStart: in-memory');

      let encoderError: Error | null = null;
      let encoderOutputCount = 0;
      videoEncoder = new VideoEncoder({
        output: (chunk, meta) => {
          encoderOutputCount++;
          muxer.addVideoChunk(chunk, meta);
        },
        error: (e) => {
          encoderError = e as Error;
          console.error('[useVideoExport] VideoEncoder Error:', e);
        },
      });
      videoEncoder.configure(videoConfig);

      if (decodedAudio && !isGif) {
        audioEncoder = new AudioEncoder({
          output: (chunk, meta) => muxer.addAudioChunk(chunk, meta),
          error: (e) => console.error('[useVideoExport] AudioEncoder error:', e),
        });
        audioEncoder.configure({ codec: 'mp4a.40.2', sampleRate: 48000, numberOfChannels: 2, bitrate: 192_000 });
      }

      // 5. é‡ç½®è§†é¢‘æ’­æ”¾
      video.pause();
      setIsPlaying(false);
      await new Promise(r => {
        const onSd = () => { video.removeEventListener('seeked', onSd); r(null); };
        video.addEventListener('seeked', onSd);
        video.currentTime = 0;
      });

      enableIncrementalMode();
      const startTime = performance.now();
      let lastProgressAt = 0;
      let encodedCount = 0;
      
      // ğŸ¯ å…³é”®ä¿®å¤ï¼šä½¿ç”¨å•è°ƒé€’å¢çš„å¸§è®¡æ•°å™¨ç”Ÿæˆæ—¶é—´æˆ³ï¼Œè€Œä¸æ˜¯ä¾èµ– mediaTime
      // è¿™æ ·å¯ä»¥ç¡®ä¿æ—¶é—´æˆ³æ°¸è¿œæ˜¯é€’å¢çš„ï¼Œé¿å… muxer æŠ¥é”™
      let frameTimestamp = 0;
      const frameDuration = 1_000_000 / fps; // å¾®ç§’ä¸ºå•ä½çš„å¸§é—´éš”

      // 6. è§†é¢‘å¯¼å‡ºå¾ªç¯ (ä½¿ç”¨ VFC åŒæ­¥)
      const vVideo = video as any;
      if (typeof vVideo.requestVideoFrameCallback === 'function') {
        console.log('[useVideoExport] Export via VFC started...');
        await new Promise<void>((resolve, reject) => {
          let vfcId: number;
          let timeoutId: NodeJS.Timeout;
          
          const cleanup = () => {
            if (vfcId != null) vVideo.cancelVideoFrameCallback(vfcId);
            if (timeoutId) clearTimeout(timeoutId);
            video.removeEventListener('ended', onEnded);
          };
          
          const onFrame = async (_: number, meta: VideoFrameCallbackMetadata) => {
            if (!isExportingRef.current || encoderError) { 
              video.pause();
              cleanup();
              reject(encoderError || new Error('Aborted')); 
              return; 
            }
            
            // æ”¹è¿›ï¼šå¢åŠ ä¸€ä¸ªå°å†—ä½™ï¼Œç¡®ä¿èƒ½æ•æ‰åˆ°æœ€åä¸€ç§’
            if (meta.mediaTime >= durationSeconds - 0.016) { 
              console.log('[useVideoExport] VFC Reached target end time:', meta.mediaTime, '/', durationSeconds);
              video.pause();
              cleanup();
              resolve(); 
              return; 
            }

            if (videoEncoder && videoEncoder.encodeQueueSize > ENCODER_QUEUE_THRESHOLD) {
              video.pause();
              while (videoEncoder.encodeQueueSize > 2) await new Promise(r => setTimeout(r, 10));
              video.play().catch(console.error);
            }

            if (encodedCount % 60 === 0) {
              console.log('[å¯¼å‡º] å‡†å¤‡æ¸²æŸ“å¸§:', { 
                frameIndex: encodedCount, 
                mediaTime: meta.mediaTime.toFixed(3),
                timestampMs: meta.mediaTime * 1000
              });
            }
            
            await renderFrame(meta.mediaTime * 1000);
            
            // ğŸ¯ è°ƒè¯•ï¼šæ£€æŸ¥ç”»å¸ƒå†…å®¹
            if (encodedCount === 0) {
              const ctx = canvas.getContext('2d');
              if (ctx) {
                const imageData = ctx.getImageData(0, 0, Math.min(10, canvas.width), Math.min(10, canvas.height));
                const hasContent = Array.from(imageData.data).some(v => v !== 0);
                console.log('[å¯¼å‡º] ç¬¬ä¸€å¸§ç”»å¸ƒæ£€æŸ¥:', {
                  canvasSize: { width: canvas.width, height: canvas.height },
                  hasContent,
                  samplePixels: Array.from(imageData.data.slice(0, 16))
                });
              }
            }
            
            const vFrame = new VideoFrame(canvas, { timestamp: frameTimestamp });
            console.log('[å¯¼å‡º] åˆ›å»ºè§†é¢‘å¸§:', {
              frameIndex: encodedCount,
              timestamp: frameTimestamp,
              mediaTime: meta.mediaTime.toFixed(3),
              frameSize: { width: vFrame.displayWidth, height: vFrame.displayHeight }
            });
            
            if (videoEncoder) {
              videoEncoder.encode(vFrame, { keyFrame: encodedCount % 60 === 0 });
            }
            vFrame.close();
            encodedCount++;
            frameTimestamp += frameDuration; // é€’å¢æ—¶é—´æˆ³

            if (encodedCount % 60 === 0) {
              console.log(`[useVideoExport] Progress - Time: ${meta.mediaTime.toFixed(2)}s, Encoded Frames: ${encodedCount}, Encoder Output: ${encoderOutputCount}`);
            }

            if (performance.now() - lastProgressAt > PROGRESS_THROTTLE_MS) {
              const progressRatio = meta.mediaTime / durationSeconds;
              const displayProgress = isGif ? progressRatio * 0.9 : progressRatio;
              setExportProgress(Math.min(0.95, displayProgress));
              lastProgressAt = performance.now();
            }
            vfcId = vVideo.requestVideoFrameCallback(onFrame);
          };

          const onEnded = () => { 
            console.log('[useVideoExport] Video native ended. Finalizing frames...');
            cleanup();
            resolve(); 
          };
          video.addEventListener('ended', onEnded);
          
          // å¢åŠ è¶…æ—¶ä¿æŠ¤åˆ° 10 ç§’ï¼Œé˜²æ­¢å¤§å‹é¡¹ç›®åå°è¿è¡Œç•¥å¾®å˜æ…¢è¢«è¯¯æ€
          timeoutId = setTimeout(() => {
            console.warn('[useVideoExport] Export timeout reached, resolving current frames.');
            video.pause();
            cleanup();
            resolve();
          }, (durationSeconds + 10) * 1000);

          vfcId = vVideo.requestVideoFrameCallback(onFrame);
          video.play().catch((err) => {
            console.error('[useVideoExport] Video play failed during export:', err);
            cleanup();
            reject(err);
          });
        });
      } else {
        // Fallback for non-VFC browsers
        console.log('[useVideoExport] VFC not supported, using manual seek fallback...');
        for (let t = 0; t < durationSeconds; t += 1/fps) {
          if (!isExportingRef.current || encoderError) break;
          video.currentTime = t;
          await new Promise(r => {
            const onSd = () => { video.removeEventListener('seeked', onSd); r(null); };
            video.addEventListener('seeked', onSd);
            setTimeout(onSd, 500); // å…œåº•å¤„ç†
          });
          await renderFrame(t * 1000);
          const vFrame = new VideoFrame(canvas, { timestamp: frameTimestamp });
          if (videoEncoder) {
            videoEncoder.encode(vFrame, { keyFrame: encodedCount % 60 === 0 });
          }
          vFrame.close();
          encodedCount++;
          frameTimestamp += frameDuration; // é€’å¢æ—¶é—´æˆ³
          
          if (performance.now() - lastProgressAt > PROGRESS_THROTTLE_MS) {
            const progressRatio = t / durationSeconds;
            const displayProgress = isGif ? progressRatio * 0.9 : progressRatio;
            setExportProgress(Math.min(0.95, displayProgress));
            lastProgressAt = performance.now();
          }
        }
      }

      // 7. éŸ³é¢‘ç¼–ç å¤„ç†
      if (audioEncoder && decodedAudio && !isGif) {
        console.log('[useVideoExport] Processing audio track...');
        const chans = decodedAudio.numberOfChannels;
        const sr = decodedAudio.sampleRate;
        const maxS = Math.floor(durationSeconds * sr);
        const STEP = 1024;
        for (let i = 0; i < maxS; i += STEP) {
          if (!isExportingRef.current) break;
          const len = Math.min(STEP, maxS - i);
          const data = new Float32Array(len * chans);
          for (let c = 0; c < chans; c++) {
            const src = decodedAudio.getChannelData(c);
            for (let s = 0; s < len; s++) {
               // è¾¹ç•Œæ£€æŸ¥ï¼šå¦‚æœè¶…å‡ºæºéŸ³é¢‘é•¿åº¦ï¼Œå¡«å……é™éŸ³ï¼Œé˜²æ­¢å™ªéŸ³ (crackling)
               const sampleIdx = i + s;
               if (sampleIdx < src.length) {
                 data[s * chans + c] = src[sampleIdx];
               } else {
                 data[s * chans + c] = 0; 
               }
            }
          }
          const ad = new AudioData({ 
            format: 'f32', 
            sampleRate: sr, 
            numberOfFrames: len, 
            numberOfChannels: chans, 
            timestamp: Math.round((i / sr) * 1_000_000), 
            data 
          });
          if (audioEncoder) {
            audioEncoder.encode(ad);
          }
          ad.close();
        }
        if (audioEncoder) {
          await audioEncoder.flush();
          audioEncoder.close();
        }
      }

      if (videoEncoder) {
        await videoEncoder.flush();
        videoEncoder.close();
      }
      console.log('[useVideoExport] VideoEncoder flushed and closed.');
      
      // å…³é”®ä¿®å¤ï¼šmuxer.finalize() ä¼šè§¦å‘å¤§é‡å¼‚æ­¥çš„ onData å›è°ƒ
      // æˆ‘ä»¬éœ€è¦åœ¨ finalize ä¹‹åå†æ¬¡ç­‰å¾… writeChain ä»¥ç¡®ä¿è¿™äº›å›è°ƒéƒ½å®Œæˆ
      console.log('[useVideoExport] Finalizing muxer (this will trigger header writes)...');
      muxer.finalize();
      
      // ç­‰å¾… finalize è§¦å‘çš„æ‰€æœ‰å†™å…¥å®Œæˆ
      console.log('[useVideoExport] Waiting for all write operations to complete...');
      await writeChain;
      
      // é¢å¤–ç­‰å¾…ä¸€ä¸ª tick ä»¥ç¡®ä¿æ‰€æœ‰ Promise éƒ½å·²è§£å†³
      await new Promise(resolve => setTimeout(resolve, 100));
      await writeChain; // å†æ¬¡ç¡®è®¤
      
      console.log(`[useVideoExport] All writes complete. Total chunks: ${chunksReceived}`);
      
      if (chunksReceived === 0 && !isGif) {
        throw new Error('EncoderProducedNoData: The file is empty. Your hardware may not support this resolution or codec.');
      }

      if (streamId) await ipc.invoke('close-export-stream', { streamId });

      if (isGif) {
        setExportProgress(0.99);
        await ipc.invoke('convert-mp4-to-gif', { inputPath: workPath, outputPath: finalPath, fps: 20 });
      }

      setExportProgress(1);
      console.log(`[useVideoExport] Export finished in ${((performance.now() - startTime) / 1000).toFixed(1)}s`);
      
      // ğŸ¯ å¯¼å‡ºå®Œæˆåæ¢å¤é¢„è§ˆé…ç½®
      console.log('[useVideoExport] Restoring preview render config...');
      if (canvas) applyRenderConfig(canvas, PREVIEW_CONFIG);
      
      return { success: true, filePath: finalPath };

    } catch (e: any) {
      console.error('[useVideoExport] Export failed:', e);
      // ç¡®ä¿æ¸…ç†èµ„æº
      try {
        if (typeof videoEncoder !== 'undefined' && videoEncoder && videoEncoder.state !== 'closed') {
          await videoEncoder.flush().catch(() => {});
          videoEncoder.close();
        }
        if (typeof audioEncoder !== 'undefined' && audioEncoder && audioEncoder.state !== 'closed') {
          await audioEncoder.flush().catch(() => {});
          audioEncoder.close();
        }
      } catch (cleanupErr) {
        console.error('[useVideoExport] Error during encoder cleanup:', cleanupErr);
      }
      if (streamId) await ipc.invoke('close-export-stream', { streamId, deleteOnClose: true }).catch(() => {});
      
      // ğŸ¯ å¯¼å‡ºå¤±è´¥åä¹Ÿè¦æ¢å¤é¢„è§ˆé…ç½®
      console.log('[useVideoExport] Restoring preview config after error...');
      if (canvas) applyRenderConfig(canvas, PREVIEW_CONFIG);
      
      return { success: false };
    } finally {
      isExportingRef.current = false;
      setIsExporting(false);
      resetCameraCache();
    }
  };

  return { handleExport, exportProgress, cancelExport };
}
