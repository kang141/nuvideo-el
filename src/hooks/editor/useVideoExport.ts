import { useState, RefObject, useRef } from 'react';
import { Muxer, StreamTarget } from 'mp4-muxer';
import { QualityConfig } from '../../constants/quality';
import { RenderGraph } from '../../types/render-graph';
import { enableIncrementalMode, resetCameraCache } from '../../core/camera-solver';

interface UseVideoExportOptions {
  videoRef: RefObject<HTMLVideoElement>;
  canvasRef: RefObject<HTMLCanvasElement>;
  maxDuration: number;
  exportDuration?: number;
  onSeek: (time: number) => void;
  setIsPlaying: (playing: boolean) => void;
  renderFrame: (timestampMs: number) => Promise<HTMLCanvasElement | null>;
  isExporting: boolean;
  setIsExporting: (v: boolean) => void;
  renderGraph?: RenderGraph;
}

const PROGRESS_THROTTLE_MS = 100;

export function useVideoExport({
  videoRef,
  canvasRef,
  maxDuration,
  exportDuration,
  onSeek: _onSeek,
  setIsPlaying,
  renderFrame,
  isExporting: _isExporting,
  setIsExporting,
  renderGraph,
}: UseVideoExportOptions) {
  const [exportProgress, setExportProgress] = useState(0);
  const isExportingRef = useRef(false);
  const LAST_DIR_KEY = 'nuvideo_last_export_dir';
  
  type RendererIPC = { invoke: (channel: string, payload?: unknown) => Promise<unknown> };
  const ipc = ((window as unknown) as { ipcRenderer?: RendererIPC }).ipcRenderer!;

  const cancelExport = () => {
    isExportingRef.current = false;
    setIsExporting(false);
    resetCameraCache();
  };

  const handleExport = async (quality?: QualityConfig, targetPath?: string | null): Promise<{ success: boolean; filePath?: string }> => {
    console.log('[useVideoExport] handleExport called', { 
      quality, 
      targetPath, 
      hasRenderGraph: !!renderGraph,
      audioTracks: renderGraph?.audio?.tracks?.length,
      videoSource: renderGraph?.videoSource 
    });
    if (renderGraph) {
      console.log('[useVideoExport] RenderGraph details:', JSON.stringify(renderGraph, (k,v) => k === 'mouse' ? undefined : v, 2));
    }

    if (isExportingRef.current) return { success: false };
    const video = videoRef.current;
    const canvas = canvasRef.current;
    if (!video || !canvas) {
      console.error('[useVideoExport] Required DOM elements missing:', { video: !!video, canvas: !!canvas });
      return { success: false };
    }
    
    let streamId: string | null = null;
    let isGif = quality?.id === 'gif' || targetPath?.toLowerCase().endsWith('.gif');
    const bitrate = isGif ? 150 * 1024 * 1024 : (quality?.bitrate || 50 * 1024 * 1024);
    const fps = 60;
    const durationSeconds = exportDuration ?? maxDuration;
    // ç¨³å®šæ€§åŠ å›ºï¼šå¼ºåˆ¶åˆ†è¾¨ç‡ä¸ºå¶æ•°ä»¥é€‚é…ç¡¬ä»¶ç¼–ç å™¨
    const width = canvas.width % 2 === 0 ? canvas.width : canvas.width - 1;
    const height = canvas.height % 2 === 0 ? canvas.height : canvas.height - 1;

    // åœ¨ try ä¹‹å‰å£°æ˜ç¼–ç å™¨å˜é‡ï¼Œä»¥ä¾¿åœ¨é”™è¯¯å¤„ç†ä¸­å¯ä»¥è®¿é—®å®ƒä»¬
    let videoEncoder: VideoEncoder | undefined = undefined;
    let audioEncoder: AudioEncoder | null = null;
    let originalWidth = canvas.width;
    let originalHeight = canvas.height;

    try {
      isExportingRef.current = true;
      setIsExporting(true);
      setExportProgress(0);

      // ğŸ”’ å¼ºåŒ–é”å®šï¼šç­‰å¾…é¢„è§ˆå¾ªç¯å®Œå…¨åœæ­¢
      // 1. ç­‰å¾… React é‡æ–°æ¸²æŸ“å¹¶æ‰§è¡Œ cleanup (1000ms è¶³å¤Ÿ 2-3 ä¸ªæ¸²æŸ“å‘¨æœŸ)
      await new Promise(r => setTimeout(r, 1000));
      
      // 2. å¼ºåˆ¶å–æ¶ˆæ‰€æœ‰å¯èƒ½æ®‹ç•™çš„ RAF å›è°ƒ
      // è¿™æ˜¯åŒä¿é™©ï¼Œé˜²æ­¢æç«¯æƒ…å†µä¸‹ useEffect cleanup æœªæ‰§è¡Œ
      for (let i = 0; i < 100; i++) cancelAnimationFrame(i);
      
      // ğŸ¨ æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„ç”»è´¨é…ç½®å†³å®šå¯¼å‡ºåˆ†è¾¨ç‡
      // å¦‚æœç”¨æˆ·é€‰æ‹©äº†"æœ€é«˜"ç”»è´¨ï¼Œä½¿ç”¨ quality.maxWidth/maxHeight
      // å¦åˆ™ä½¿ç”¨ 1920x1080 ä½œä¸ºé»˜è®¤å€¼
      const exportWidth = quality?.maxWidth || 1920;
      const exportHeight = quality?.maxHeight || 1080;
      
      console.log(`[useVideoExport] Quality: ${quality?.label || 'Default'}, Target Resolution: ${exportWidth}x${exportHeight}, Bitrate: ${(quality?.bitrate || 0) / 1_000_000}Mbps`);
      
      // æ›´æ–°åŸå§‹å°ºå¯¸å¼•ç”¨
      originalWidth = canvas.width;
      originalHeight = canvas.height;
      
      // è®¾ç½®å¯¼å‡ºåˆ†è¾¨ç‡
      canvas.width = exportWidth;
      canvas.height = exportHeight;
      console.log(`[useVideoExport] Canvas resized to export resolution: ${exportWidth}x${exportHeight}`);

      // ğŸ¨ å…³é”®ä¿®å¤ï¼šå¯¼å‡ºæ¨¡å¼ä¸‹å¿…é¡»æ ¹æ®å¯¼å‡ºåˆ†è¾¨ç‡é‡æ–°ç”Ÿæˆç¦»å±èƒŒæ™¯å±‚
      // å¦åˆ™ 2K å¯¼å‡ºå¯èƒ½ä¼šä½¿ç”¨é¢„è§ˆæ—¶çš„ç¼“å­˜ï¼Œå¯¼è‡´èƒŒæ™¯æ¨¡ç³Šæˆ–å¸ƒå±€åç§»
      if ((window as any).updateOffscreen) {
        (window as any).updateOffscreen(exportWidth, exportHeight, video.videoWidth || 1920, video.videoHeight || 1080);
      }
      
      // 1. ç¡®å®šä¿å­˜è·¯å¾„
      let finalPath = targetPath;
      if (!finalPath) {
        const ext = isGif ? '.gif' : '.mp4';
        const suggestName = `nuvideo_export_${Date.now()}${ext}`;
        const saveResult = await ipc.invoke('show-save-dialog', { defaultName: suggestName }) as { canceled: boolean; filePath?: string };
        if (saveResult.canceled || !saveResult.filePath) throw new Error('CanceledByUser');
        finalPath = saveResult.filePath;
        const lastSlashIndex = Math.max(finalPath.lastIndexOf('/'), finalPath.lastIndexOf('\\'));
        if (lastSlashIndex > -1) {
          const dir = finalPath.substring(0, lastSlashIndex);
          localStorage.setItem(LAST_DIR_KEY, dir);
        }
      }

      isGif = finalPath!.toLowerCase().endsWith('.gif');
      const workPath = isGif ? finalPath!.replace(/\.(gif|mp4)$/i, '') + `.temp_${Date.now()}.mp4` : finalPath!;

      // 2. é¢„è§£ç å¹¶æ··åˆéŸ³è½¨ï¼ˆGIFæ¨¡å¼è·³è¿‡éŸ³é¢‘å¤„ç†ï¼‰
      let decodedAudio: AudioBuffer | null = null;
      console.log('[useVideoExport] Entering audio processing block...');
      
      if (renderGraph?.audio?.tracks && !isGif) {
        try {
          const audioCtx = new AudioContext({ sampleRate: 48000 });
          const totalSamples = Math.ceil(durationSeconds * 48000);
          const mixedBuffer = audioCtx.createBuffer(2, totalSamples, 48000);
          
          let hasAnyAudio = false;
          const tracks = renderGraph.audio.tracks;
          console.log('[useVideoExport] Audio mixing start. Track count:', tracks.length, 'Duration:', durationSeconds);

          if (tracks.length === 0) {
            console.warn('[useVideoExport] Audio track list is EMPTY.');
          }

          for (const track of tracks) {
            const trackPath = track.path || track.filePath;
            if (!trackPath) {
              console.warn('[useVideoExport] Track missing path:', track);
              continue;
            }

            const targetUrl = trackPath;
            console.log(`[useVideoExport] Processing track: ${track.source}, URL: ${targetUrl}`);
            
            try {
              const resp = await fetch(targetUrl);
              if (!resp.ok) {
                console.error(`[useVideoExport] Fetch failed for ${track.source}: ${resp.status} ${resp.statusText}`);
                continue;
              }
              const arrayBuffer = await resp.arrayBuffer();
              console.log(`[useVideoExport] Decoded raw size: ${arrayBuffer.byteLength} bytes`);
              
              const trackBuffer = await audioCtx.decodeAudioData(arrayBuffer);
              console.log(`[useVideoExport] Track decoded: ${track.source}, Duration: ${trackBuffer.duration.toFixed(2)}s, Channels: ${trackBuffer.numberOfChannels}`);
              
              // æ··åˆåˆ° mixedBuffer
              const startOffset = Math.max(0, Math.floor(((track.startTime || 0) + (renderGraph.audioDelay || 0)) / 1000 * 48000));
              const vol = track.volume ?? 1.0;
              console.log(`[useVideoExport] Mixing ${track.source} at offset: ${startOffset}, volume: ${vol}`);
              
              for (let channel = 0; channel < Math.min(mixedBuffer.numberOfChannels, trackBuffer.numberOfChannels); channel++) {
                const targetData = mixedBuffer.getChannelData(channel);
                const sourceData = trackBuffer.getChannelData(channel);
                const copyLen = Math.min(sourceData.length, targetData.length - startOffset);
                
                // æ·»åŠ è¾¹ç•Œæ£€æŸ¥ï¼Œé˜²æ­¢æ•°ç»„è¶Šç•Œ
                for (let i = 0; i < copyLen; i++) {
                  const targetIdx = startOffset + i;
                  if (targetIdx >= 0 && targetIdx < targetData.length) {
                    targetData[targetIdx] += sourceData[i] * vol;
                  }
                }
              }
              hasAnyAudio = true;
            } catch (trackErr) {
              console.error(`[useVideoExport] Critical error mixing track ${track.source}:`, trackErr);
            }
          }
          
          if (hasAnyAudio) {
            let maxAmp = 0;
            const testData = mixedBuffer.getChannelData(0);
            for (let i = 0; i < Math.min(testData.length, 100000); i += 100) {
              maxAmp = Math.max(maxAmp, Math.abs(testData[i]));
            }
            console.log(`[useVideoExport] Audio mixing complete. Max amplitude sample: ${maxAmp.toFixed(4)}`);
            decodedAudio = mixedBuffer;
          } else {
            console.warn('[useVideoExport] No audio tracks were successfully processed.');
          }
        } catch (e) {
          console.error('[useVideoExport] Audio mixing crash:', e);
        }
      } else {
        console.warn('[useVideoExport] renderGraph.audio or .tracks is missing!');
      }

      // 3. å‡†å¤‡ç¼–ç å™¨æ¢æµ‹
      const codecCandidates = isGif 
        ? ['vp09.00.10.08'] 
        : [
            'avc1.640033', // High Profile, Level 5.1 (æ”¯æŒ 4K)
            'avc1.4d0033', // Main Profile, Level 5.1 (æ”¯æŒ 4K)
            'avc1.42E034', // Baseline Profile, Level 5.2 (æé«˜å…¼å®¹æ€§ï¼Œä¸”æ”¯æŒè¶…å¤§åˆ†è¾¨ç‡)
          ];
      
      let videoConfig: VideoEncoderConfig | null = null;
      for (const codec of codecCandidates) {
        const testConfig: VideoEncoderConfig = { 
          codec, width, height, bitrate, framerate: fps, 
          hardwareAcceleration: 'prefer-hardware' 
        };
        try {
          const support = await VideoEncoder.isConfigSupported(testConfig);
          if (support.supported) {
            videoConfig = testConfig;
            console.log('[useVideoExport] Selected codec:', codec);
            break;
          }
        } catch (err) {
          console.warn(`[useVideoExport] Codec ${codec} not supported:`, err);
        }
      }
      
      if (!videoConfig) {
        // å¦‚æœæ‰€æœ‰é«˜çº§é…ç½®éƒ½å¤±è´¥ï¼Œä½¿ç”¨ H.264 Baseline Profile, Level 5.1
        // Level 5.1 å®Œç¾æ”¯æŒ 1080p/4K @ 60fpsï¼Œå¸¦å®½å……è¶³ï¼Œæ’­æ”¾æµç•…
        // å›å½’ Baseline Profile ä»¥ä¿è¯ 100% å…¼å®¹æ€§ï¼Œé˜²æ­¢ Encoder creation error
        console.warn('[useVideoExport] All advanced codecs failed, using H.264 Baseline Level 5.1');
        videoConfig = { 
          codec: 'avc1.42E033', // Baseline Profile, Level 5.1
          width, 
          height, 
          bitrate, 
          framerate: fps, 
          hardwareAcceleration: 'no-preference' // è®©æµè§ˆå™¨è‡ªåŠ¨é€‰æ‹©æœ€ä½³å®ç°
        };
      }

      // 4. æ‰“å¼€æµä¸ Muxer
      const openResult = await ipc.invoke('open-export-stream', { targetPath: workPath }) as { success: boolean; streamId?: string; error?: string };
      if (!openResult.success) throw new Error(`StreamOpenFailed: ${openResult.error}`);
      streamId = openResult.streamId || null;

      let writeChain = Promise.resolve();
      let chunksReceived = 0;
      let lastWriteLog = 0;

      const muxerTarget = new StreamTarget({
        onData: (chunk, position) => {
          const chunkLen = chunk.length;
          writeChain = writeChain.then(() => 
            ipc.invoke('write-export-chunk', { streamId, chunk, position })
          ).then(() => { 
            chunksReceived++;
            if (typeof position !== 'number') {
              if (performance.now() - lastWriteLog > 1000) {
                console.log(`[useVideoExport] Writing... Total chunks: ${chunksReceived}, last size: ${chunkLen}`);
                lastWriteLog = performance.now();
              }
            } else {
              console.log(`[useVideoExport] Header backfill at: ${position}, size: ${chunkLen}`);
            }
          }).catch(err => console.error('[useVideoExport] Write Error:', err));
        }
      });

      const muxer = new Muxer({
        target: muxerTarget as any,
        video: { codec: (videoConfig.codec.startsWith('vp') ? 'vp9' : 'avc') as any, width, height, frameRate: fps },
        audio: decodedAudio && !isGif ? { codec: 'aac', sampleRate: 48000, numberOfChannels: 2 } : undefined,
        fastStart: 'in-memory', // æ”¹ä¸ºå†…å­˜ç¼“å†²æ¨¡å¼ï¼Œå¯¹äºçŸ­è§†é¢‘ï¼ˆæ•°åˆ†é’Ÿå†…ï¼‰æ¥è¯´æ›´ç¨³å®šï¼Œé¿å…å›å¡«å¤±è´¥
        firstTimestampBehavior: 'offset',
      });
      console.log('[useVideoExport] Muxer initialized with fastStart: in-memory');

      let encoderError: Error | null = null;
      let encoderOutputCount = 0;
      videoEncoder = new VideoEncoder({
        output: (chunk, meta) => {
          encoderOutputCount++;
          muxer.addVideoChunk(chunk, meta);
        },
        error: (e) => {
          encoderError = e as Error;
          console.error('[useVideoExport] VideoEncoder Error:', e);
        },
      });
      videoEncoder.configure(videoConfig);

      if (decodedAudio && !isGif) {
        audioEncoder = new AudioEncoder({
          output: (chunk, meta) => muxer.addAudioChunk(chunk, meta),
          error: (e) => console.error('[useVideoExport] AudioEncoder error:', e),
        });
        audioEncoder.configure({ codec: 'mp4a.40.2', sampleRate: 48000, numberOfChannels: 2, bitrate: 192_000 });
      }

      // 5. é‡ç½®è§†é¢‘æ’­æ”¾
      video.pause();
      setIsPlaying(false);
      await new Promise(r => {
        const onSd = () => { video.removeEventListener('seeked', onSd); r(null); };
        video.addEventListener('seeked', onSd);
        video.currentTime = 0;
      });

      enableIncrementalMode();
      const startTime = performance.now();
      let lastProgressAt = 0;
      let encodedCount = 0;

      // 6. è§†é¢‘å¯¼å‡ºå¾ªç¯ (ç¦»çº¿æ¸²æŸ“æ¨¡å¼ - æ¯ä¸€å¸§éƒ½å¿…é¡»æ¸²æŸ“)
      // ä¸å†ä½¿ç”¨ video.play() + VFCï¼Œè€Œæ˜¯æ‰‹åŠ¨æ§åˆ¶æ—¶é—´è½´
      console.log('[useVideoExport] Starting Offline Rendering Loop...');
      
      const frameDuration = 1 / fps;
      const totalFrames = Math.ceil(durationSeconds * fps);
      let lastReportTime = performance.now();

      // ğŸ¯ ä¼˜åŒ–ç‚¹ï¼šåœ¨å¾ªç¯å¤–å‡†å¤‡å¥½èƒŒæ™¯å¡«å…… Canvasï¼Œé¿å…æ¯å¸§é‡å¤åˆ›å»º (å‡å°‘ GC å‹åŠ›)
      const tempCanvas = document.createElement('canvas');
      tempCanvas.width = canvas.width;
      tempCanvas.height = canvas.height;
      const tCtx = tempCanvas.getContext('2d', { alpha: false });

      for (let frameIdx = 0; frameIdx < totalFrames; frameIdx++) {
        if (!isExportingRef.current || encoderError) {
          throw encoderError || new Error('Aborted by user');
        }

        const currentTime = frameIdx * frameDuration;
        const timestampMicros = Math.round(currentTime * 1_000_000);

        // A. æ¸²æŸ“è¿™ä¸€å¸§
        // ğŸ¯ å…³é”®å˜åŒ–ï¼šrenderFrame ç°åœ¨è¿”å›ä¸€ä¸ªç‹¬ç«‹çš„ç¦»å± Canvas å¼•ç”¨
        const renderedCanvas = await renderFrame(currentTime * 1000);
        if (!renderedCanvas) {
          console.warn(`[useVideoExport] Frame ${frameIdx} render returned null, skipping...`);
          frameIdx++;
          continue;
        }

        // B. ä» Canvas æŠ“å–å›¾åƒ (ç¡®ä¿ä¸é€æ˜åº•è‰²å¤„ç†åœ¨ç‹¬ç«‹çš„ç¦»å±ç¯å¢ƒä¸­å®Œæˆ)
        if (tCtx) {
          tCtx.fillStyle = '#0a0a0a'; 
          tCtx.fillRect(0, 0, exportWidth, exportHeight);
          tCtx.drawImage(renderedCanvas, 0, 0);
        }
        
        const frame = new VideoFrame(tempCanvas, { 
          timestamp: timestampMicros,
          duration: Math.round(frameDuration * 1_000_000),
          alpha: 'discard'
        });
        
        if (videoEncoder) {
          // å…³é”®å¸§ç­–ç•¥ï¼šæ¯ 2ç§’ (120å¸§) ä¸€ä¸ªå…³é”®å¸§ï¼Œå¹³è¡¡æ‹–åŠ¨æ€§èƒ½ä¸ä½“ç§¯
          // æˆ–è€…æ¯ 0.5ç§’ (30å¸§) ä»¥è·å¾—æ›´å¥½çš„ç¼–è¾‘ä½“éªŒ
          videoEncoder.encode(frame, { keyFrame: frameIdx % 60 === 0 });
        }
        frame.close();
        
        encodedCount++;

        // C. è¿›åº¦æ±‡æŠ¥ (èŠ‚æµ)
        // ä¸ºäº†æ¶ˆé™¤èµ·æ­¥é˜¶æ®µçš„â€œæ­»æœºæ„Ÿâ€ï¼Œè¿›åº¦æ¡ç»“åˆäº†æ¸²æŸ“è¿›åº¦(30%)å’Œå®é™…ç¼–ç è¿›åº¦(70%)ã€‚
        if (performance.now() - lastReportTime > PROGRESS_THROTTLE_MS) {
          const renderProgress = (frameIdx + 1) / totalFrames;
          const encodeProgress = encoderOutputCount / totalFrames;
          const mixedProgress = renderProgress * 0.3 + encodeProgress * 0.7;
          
          const displayProgress = isGif ? mixedProgress * 0.9 : mixedProgress;
          setExportProgress(Math.min(0.99, displayProgress));
          // è°ƒè¯•æ—¥å¿—ä¿ç•™ç¼–ç é˜Ÿåˆ—å¤§å°ï¼Œç›‘æ§ç¨³å®šæ€§
          console.log(`[useVideoExport] Render:${(renderProgress*100).toFixed(0)}% Encode:${(encodeProgress*100).toFixed(0)}% Queue:${videoEncoder?.encodeQueueSize}`);
          lastReportTime = performance.now();
          
          await new Promise(r => setTimeout(r, 0));
        }

        // ğŸ¯ æ ¸å¿ƒæé€Ÿç‚¹ï¼šç”Ÿäº§è€…-æ¶ˆè´¹è€…æµæ°´çº¿ç§¯å‹ä¿æŠ¤
        // å½“ç¼–ç å™¨é˜Ÿåˆ—è¿‡å¤§æ—¶ï¼Œæš‚åœä¸€ä¸‹è®©ç¼–ç å™¨æ¶ˆåŒ–
        // ğŸ”¥ å…³é”®ä¿®å¤ï¼šä¸è¦ç”¨ while å¾ªç¯ï¼Œä¼šå¯¼è‡´å¯¼å‡ºææ…¢ï¼
        if (videoEncoder && videoEncoder.encodeQueueSize > 64) {
           // å•æ¬¡ç­‰å¾…ï¼Œè®©å‡ºæ§åˆ¶æƒç»™ç¼–ç å™¨
           await new Promise(r => setTimeout(r, 10)); 
        }
      }

      // 7. éŸ³é¢‘ç¼–ç å¤„ç†
      if (audioEncoder && decodedAudio && !isGif) {
        console.log('[useVideoExport] Processing audio track...');
        const chans = decodedAudio.numberOfChannels;
        const sr = decodedAudio.sampleRate;
        const maxS = Math.floor(durationSeconds * sr);
        const STEP = 1024;
        for (let i = 0; i < maxS; i += STEP) {
          if (!isExportingRef.current) break;
          const len = Math.min(STEP, maxS - i);
          const data = new Float32Array(len * chans);
          for (let c = 0; c < chans; c++) {
            const src = decodedAudio.getChannelData(c);
            for (let s = 0; s < len; s++) {
               // è¾¹ç•Œæ£€æŸ¥ï¼šå¦‚æœè¶…å‡ºæºéŸ³é¢‘é•¿åº¦ï¼Œå¡«å……é™éŸ³ï¼Œé˜²æ­¢å™ªéŸ³ (crackling)
               const sampleIdx = i + s;
               if (sampleIdx < src.length) {
                 data[s * chans + c] = src[sampleIdx];
               } else {
                 data[s * chans + c] = 0; 
               }
            }
          }
          const ad = new AudioData({ 
            format: 'f32', 
            sampleRate: sr, 
            numberOfFrames: len, 
            numberOfChannels: chans, 
            timestamp: Math.round((i / sr) * 1_000_000), 
            data 
          });
          if (audioEncoder) {
            audioEncoder.encode(ad);
          }
          ad.close();
        }
        if (audioEncoder) {
          await audioEncoder.flush(); 
          audioEncoder.close();
        }
      }

      if (videoEncoder) {
        await videoEncoder.flush();
        videoEncoder.close();
      }
      console.log('[useVideoExport] VideoEncoder flushed and closed.');
      
      // å…³é”®ä¿®å¤ï¼šmuxer.finalize() ä¼šè§¦å‘å¤§é‡å¼‚æ­¥çš„ onData å›è°ƒ
      // æˆ‘ä»¬éœ€è¦åœ¨ finalize ä¹‹åå†æ¬¡ç­‰å¾… writeChain ä»¥ç¡®ä¿è¿™äº›å›è°ƒéƒ½å®Œæˆ
      console.log('[useVideoExport] Finalizing muxer (this will trigger header writes)...');
      muxer.finalize();
      
      // ç­‰å¾… finalize è§¦å‘çš„æ‰€æœ‰å†™å…¥å®Œæˆ
      console.log('[useVideoExport] Waiting for all write operations to complete...');
      await writeChain;
      
      // é¢å¤–ç­‰å¾…ä¸€ä¸ª tick ä»¥ç¡®ä¿æ‰€æœ‰ Promise éƒ½å·²è§£å†³
      await new Promise(resolve => setTimeout(resolve, 100));
      await writeChain; // å†æ¬¡ç¡®è®¤
      
      console.log(`[useVideoExport] All writes complete. Total chunks: ${chunksReceived}`);
      
      if (chunksReceived === 0 && !isGif) {
        throw new Error('EncoderProducedNoData: The file is empty. Your hardware may not support this resolution or codec.');
      }

      if (streamId) await ipc.invoke('close-export-stream', { streamId });

      if (isGif) {
        setExportProgress(0.99);
        await ipc.invoke('convert-mp4-to-gif', { inputPath: workPath, outputPath: finalPath, fps: 20 });
      }

      setExportProgress(1);
      console.log(`[useVideoExport] Export finished in ${((performance.now() - startTime) / 1000).toFixed(1)}s`);
      return { success: true, filePath: finalPath };

    } catch (e: any) {
      console.error('[useVideoExport] Export failed:', e);
      // ç¡®ä¿æ¸…ç†èµ„æº
      try {
        if (typeof videoEncoder !== 'undefined' && videoEncoder && videoEncoder.state !== 'closed') {
          videoEncoder.flush();
          videoEncoder.close();
        }
        if (typeof audioEncoder !== 'undefined' && audioEncoder && audioEncoder.state !== 'closed') {
          audioEncoder.flush();
          audioEncoder.close();
        }
      } catch (cleanupErr) {
        console.error('[useVideoExport] Error during encoder cleanup:', cleanupErr);
      }
      if (streamId) await ipc.invoke('close-export-stream', { streamId, deleteOnClose: true }).catch(() => {});
      return { success: false };
    } finally {
      // æ¢å¤ Canvas åˆ°é¢„è§ˆåˆ†è¾¨ç‡
      if (canvas) {
        canvas.width = originalWidth;
        canvas.height = originalHeight;
        console.log(`[useVideoExport] Canvas restored to preview resolution: ${originalWidth}x${originalHeight}`);
      }
      
      isExportingRef.current = false;
      setIsExporting(false);
      resetCameraCache();
    }
  };

  return { handleExport, exportProgress, cancelExport };
}
