import { useState, RefObject, useRef } from 'react';
import { Muxer, StreamTarget } from 'mp4-muxer';
import { QualityConfig, DEFAULT_QUALITY } from '../../constants/quality';
import { RenderGraph } from '../../types/render-graph';
import { enableIncrementalMode, resetCameraCache } from '../../core/camera-solver';
import { applyRenderConfig, EXPORT_CONFIG, PREVIEW_CONFIG } from '../../core/render-config';

interface UseVideoExportOptions {
  videoRef: RefObject<HTMLVideoElement>;
  canvasRef: RefObject<HTMLCanvasElement>;
  maxDuration: number;
  exportDuration?: number;
  onSeek: (time: number) => void;
  setIsPlaying: (playing: boolean) => void;
  setIsExporting: (v: boolean) => void;
  renderGraph?: RenderGraph;
  bgCategory?: string;
  bgFile?: string;
  renderFrame: (t: number) => Promise<void>;
}

const ENCODER_QUEUE_THRESHOLD = 128; // è¿›ä¸€æ­¥å¢å¤§é˜Ÿåˆ—ï¼Œå…è®¸æ¸²æŸ“è·‘å¾—æ›´è¶…å‰
const PROGRESS_THROTTLE_MS = 100;
const IPC_WRITE_BATCH_SIZE = 32; // æ‰¹é‡å†™å…¥é˜ˆå€¼

export function useVideoExport({
  videoRef,
  canvasRef,
  maxDuration,
  exportDuration,
  onSeek: _onSeek,
  setIsPlaying,
  setIsExporting,
  renderGraph,
  bgCategory,
  bgFile,
  renderFrame,
}: UseVideoExportOptions) {
  const [exportProgress, setExportProgress] = useState(0);
  const isExportingRef = useRef(false);
  const LAST_DIR_KEY = 'nuvideo_last_export_dir';
  
  type RendererIPC = { invoke: (channel: string, payload?: unknown) => Promise<unknown> };
  const ipc = ((window as unknown) as { ipcRenderer?: RendererIPC }).ipcRenderer!;

    const cancelExport = () => {
    isExportingRef.current = false;
    setIsExporting(false);
    resetCameraCache();
    // é‡ç½®æ’­æ”¾é€Ÿç‡
    if (videoRef.current) videoRef.current.playbackRate = 1.0;
    // é‡ç½®ä»»åŠ¡æ è¿›åº¦
    (window as any).ipcRenderer.send('set-progress-bar', -1);
  };

  const handleExport = async (quality?: QualityConfig, targetPath?: string | null): Promise<{ success: boolean; filePath?: string }> => {
    if (isExportingRef.current) return { success: false };
    const video = videoRef.current;
    const canvas = canvasRef.current;
    if (!video || !canvas) {
      console.error('[useVideoExport] Required DOM elements missing:', { video: !!video, canvas: !!canvas });
      return { success: false };
    }
    
    
    // 4. 2026 æè‡´é€Ÿåº¦ä¼˜åŒ–ï¼šæ ¹æ®è´¨é‡åŠ¨æ€è°ƒæ•´ç”»å¸ƒç‰©ç†åˆ†è¾¨ç‡
    const targetQuality = quality || DEFAULT_QUALITY;
    const baseWidth = EXPORT_CONFIG.canvasWidth;
    const baseHeight = EXPORT_CONFIG.canvasHeight;
    
    // è®¡ç®—ç¼©æ”¾æ¯”ï¼ˆDPRï¼‰ï¼Œç¡®ä¿å¯¼å‡ºåˆ†è¾¨ç‡ä¸è¶…è¿‡é€‰å®šè´¨é‡
    const scale = Math.min(1, targetQuality.maxWidth / baseWidth, targetQuality.maxHeight / baseHeight);
    
    // åŠ¨æ€åº”ç”¨æ¸²æŸ“é…ç½®
    applyRenderConfig(canvas, {
      ...EXPORT_CONFIG,
      dpr: scale
    });
   
    let streamId: string | null = null;
    let isGif = quality?.id === 'gif' || targetPath?.toLowerCase().endsWith('.gif');
    const bitrate = isGif ? 150 * 1024 * 1024 : (targetQuality.bitrate || 50 * 1024 * 1024);
    const fps = 60;
    const durationSeconds = exportDuration ?? maxDuration;
    
    // ğŸ¯ ç‰©ç†ç¼–ç åˆ†è¾¨ç‡ï¼šå¿…é¡»åŸºäº base * scale ä¸”ä¸ºå¶æ•°
    const width = Math.floor(baseWidth * scale / 2) * 2;
    const height = Math.floor(baseHeight * scale / 2) * 2;

    // åœ¨ try ä¹‹å‰å£°æ˜ç¼–ç å™¨å˜é‡ï¼Œä»¥ä¾¿åœ¨é”™è¯¯å¤„ç†ä¸­å¯ä»¥è®¿é—®å®ƒä»¬
    let videoEncoder: VideoEncoder | undefined = undefined;
    let audioEncoder: AudioEncoder | null = null;

    try {
      isExportingRef.current = true;
      setIsExporting(true);
      setExportProgress(0);

      // 1. ç¡®å®šä¿å­˜è·¯å¾„
      let finalPath = targetPath;
      if (!finalPath) {
        const ext = isGif ? '.gif' : '.mp4';
        const suggestName = `nuvideo_export_${Date.now()}${ext}`;
        const saveResult = await ipc.invoke('show-save-dialog', { defaultName: suggestName }) as { canceled: boolean; filePath?: string };
        if (saveResult.canceled || !saveResult.filePath) throw new Error('CanceledByUser');
        finalPath = saveResult.filePath;
        const lastSlashIndex = Math.max(finalPath.lastIndexOf('/'), finalPath.lastIndexOf('\\'));
        if (lastSlashIndex > -1) {
          const dir = finalPath.substring(0, lastSlashIndex);
          localStorage.setItem(LAST_DIR_KEY, dir);
        }
      }

      isGif = finalPath!.toLowerCase().endsWith('.gif');
      const workPath = isGif ? finalPath!.replace(/\.(gif|mp4)$/i, '') + `.temp_${Date.now()}.mp4` : finalPath!;

      let decodedAudio: AudioBuffer | null = null;
      
      if (renderGraph?.audio?.tracks && !isGif) {
        try {
          const audioCtx = new AudioContext({ sampleRate: 48000 });
          const totalSamples = Math.ceil(durationSeconds * 48000);
          const mixedBuffer = audioCtx.createBuffer(2, totalSamples, 48000);
          
          let hasAnyAudio = false;
          const tracks = renderGraph.audio.tracks;
          // åªå¤„ç†å¯ç”¨çš„éŸ³é¢‘è½¨é“
          const enabledTracks = tracks.filter(t => t.enabled !== false);
          console.log('[useVideoExport] Audio mixing start. Track count:', tracks.length, 'Enabled:', enabledTracks.length, 'Duration:', durationSeconds);

          if (enabledTracks.length === 0) {
            console.warn('[useVideoExport] No enabled audio tracks.');
          }

          // ğŸ¯ å¹¶è¡ŒåŒ–éŸ³é¢‘è½¨é“è·å–ä¸è§£ç 
          await Promise.all(enabledTracks.map(async (track) => {
            const trackPath = track.path || track.filePath;
            if (!trackPath) return;

            try {
              const resp = await fetch(trackPath);
              if (!resp.ok) return;
              
              const arrayBuffer = await resp.arrayBuffer();
              const trackBuffer = await audioCtx.decodeAudioData(arrayBuffer);
              
              // æ··åˆåˆ° mixedBufferï¼ˆJSå•çº¿ç¨‹ç¯å¢ƒä¸‹ï¼Œåªè¦ä»£ç æ®µå†…æ²¡æœ‰ awaitï¼Œæ­¤å¤„ç´¯åŠ æ˜¯å®‰å…¨çš„ï¼‰
              const startOffset = Math.max(0, Math.floor(((track.startTime || 0) + (renderGraph.audioDelay || 0)) / 1000 * 48000));
              const vol = track.volume ?? 1.0;
              
              for (let channel = 0; channel < Math.min(mixedBuffer.numberOfChannels, trackBuffer.numberOfChannels); channel++) {
                const targetData = mixedBuffer.getChannelData(channel);
                const sourceData = trackBuffer.getChannelData(channel);
                const copyLen = Math.min(sourceData.length, targetData.length - startOffset);
                
                for (let i = 0; i < copyLen; i++) {
                  const targetIdx = startOffset + i;
                  if (targetIdx >= 0 && targetIdx < targetData.length) {
                    targetData[targetIdx] += sourceData[i] * vol;
                  }
                }
              }
              hasAnyAudio = true;
            } catch (trackErr) {
              console.error(`[useVideoExport] Error mixing track:`, trackErr);
            }
          }));
          
          if (hasAnyAudio) {
            decodedAudio = mixedBuffer;
          } else {
            console.warn('[useVideoExport] No audio tracks were successfully processed.');
          }
        } catch (e) {
          console.error('[useVideoExport] Audio mixing crash:', e);
        }
      } else {
        console.warn('[useVideoExport] renderGraph.audio or .tracks is missing!');
      }

      // 3. 2026 æè‡´ç²¾ç®€ï¼šä¼˜å…ˆå°è¯•ç¡¬ä»¶åŠ é€Ÿçš„å¸¸ç”¨ç¼–ç å™¨
      
      let videoConfig: VideoEncoderConfig | null = null;
      const accelModes: HardwareAcceleration[] = ['prefer-hardware', 'no-preference'];
      
      const allCandidates = [
        // H.264 å€™é€‰
        { codec: 'avc1.640033', name: 'H.264 High' },
        { codec: 'avc1.4d0033', name: 'H.264 Main' },
        { codec: 'avc1.42e033', name: 'H.264 Baseline' },
        // HEVC å€™é€‰ (3060 æ”¯æŒéå¸¸æ£’)
        { codec: 'hvc1.1.6.L120.B0', name: 'HEVC Main' },
        { codec: 'hev1.1.6.L120.B0', name: 'HEVC Main (alt)' },
      ];

      findConfig: for (const accel of accelModes) {
        for (const item of allCandidates) {
          const testConfig: VideoEncoderConfig = { 
            codec: item.codec, width, height, bitrate, framerate: fps, 
            hardwareAcceleration: accel
          };
          try {
            const support = await VideoEncoder.isConfigSupported(testConfig);
            if (support.supported) {
              videoConfig = { ...testConfig, ...support.config };
              console.log(`[useVideoExport] âœ… Selected: ${item.name} (${item.codec}) with ${accel}`);
              break findConfig;
            }
          } catch (err) {
            console.warn(`[useVideoExport] âŒ ${item.name} with ${accel} failed:`, err);
          }
        }
      }
      
      if (!videoConfig) {
        console.error('[useVideoExport] All codec candidates failed. System info:', {
          gpu: (window.navigator as any).gpu ? 'WebGPU avail' : 'No WebGPU',
          userAgent: navigator.userAgent
        });
        throw new Error('H.264/HEVC encoding is not supported on this system. Please check your GPU drivers.');
      }

      // 4. æ‰“å¼€æµä¸ Muxer
      const openResult = await ipc.invoke('open-export-stream', { targetPath: workPath }) as { success: boolean; streamId?: string; error?: string };
      if (!openResult.success) throw new Error(`StreamOpenFailed: ${openResult.error}`);
      streamId = openResult.streamId || null;

      let writeChain = Promise.resolve();
      let chunksReceived = 0;
      let chunkBuffer: { chunk: any; position: number | undefined }[] = [];

      const flushChunks = async () => {
        if (chunkBuffer.length === 0) return;
        const currentBatch = [...chunkBuffer];
        chunkBuffer = [];
        
        writeChain = writeChain.then(async () => {
          // åªæœ‰è¿ç»­çš„ append æ“ä½œæ‰åˆå¹¶ï¼Œå¸¦ position çš„ï¼ˆå¦‚ moovï¼‰å¿…é¡»å•ç‹¬å‘ä»¥é˜²ä¹±åº
          // ä½†ç”±äº WebCodecs ä¸»è¦æ˜¯é¡ºåº appendï¼Œè¿™é‡Œåšç®€å•çš„æ‰¹å¤„ç†
          await ipc.invoke('write-export-chunks-batch', { streamId, chunks: currentBatch });
          chunksReceived += currentBatch.length;
        }).catch(err => console.error('[useVideoExport] Batch Write Error:', err));
      };

      const muxerTarget = new StreamTarget({
        onData: (chunk, position) => {
          chunkBuffer.push({ chunk, position });
          
          if (chunkBuffer.length >= IPC_WRITE_BATCH_SIZE || typeof position === 'number') {
            void flushChunks();
          }
        }
      });

      const muxer = new Muxer({
        target: muxerTarget as any,
        video: { 
          codec: 'avc', 
          width, 
          height, 
          frameRate: fps 
        },
        audio: decodedAudio && !isGif ? { codec: 'aac', sampleRate: 48000, numberOfChannels: 2 } : undefined,
        fastStart: 'in-memory', // æ”¹ä¸ºå†…å­˜ç¼“å†²æ¨¡å¼ï¼Œå¯¹äºçŸ­è§†é¢‘ï¼ˆæ•°åˆ†é’Ÿå†…ï¼‰æ¥è¯´æ›´ç¨³å®šï¼Œé¿å…å›å¡«å¤±è´¥
        firstTimestampBehavior: 'offset',
      });
      console.log('[useVideoExport] Muxer initialized with fastStart: in-memory');

      let encoderError: Error | null = null;
      let encoderOutputCount = 0;
      videoEncoder = new VideoEncoder({
        output: (chunk, meta) => {
          encoderOutputCount++;
          muxer.addVideoChunk(chunk, meta);
        },
        error: (e) => {
          encoderError = e as Error;
          console.error('[useVideoExport] VideoEncoder Error:', e);
        },
      });
      videoEncoder.configure(videoConfig);

      if (decodedAudio && !isGif) {
        audioEncoder = new AudioEncoder({
          output: (chunk, meta) => muxer.addAudioChunk(chunk, meta),
          error: (e) => console.error('[useVideoExport] AudioEncoder error:', e),
        });
        audioEncoder.configure({ codec: 'mp4a.40.2', sampleRate: 48000, numberOfChannels: 2, bitrate: 192_000 });
      }

      // 5. é‡ç½®è§†é¢‘æ’­æ”¾
      video.pause();
      setIsPlaying(false);
      await new Promise(r => {
        const onSd = () => { video.removeEventListener('seeked', onSd); r(null); };
        video.addEventListener('seeked', onSd);
        video.currentTime = 0;
      });

      enableIncrementalMode();
      const startTime = performance.now();
      let lastProgressAt = 0;
      let encodedCount = 0;
      
      if (!renderGraph) {
        throw new Error('RenderGraph is required for export');
      }

      console.log('[å¯¼å‡º] æ­£åœ¨åŠ è½½æ¸²æŸ“èµ„æº...');
      
      // åŠ è½½èƒŒæ™¯å›¾ï¼ˆä» Props è·å–ï¼Œå¸¦é»˜è®¤å€¼å…œåº•ï¼‰
      const bgImage = new Image();
      const cat = bgCategory || 'macOS';
      const file = bgFile || 'sequoia-dark.jpg';
      await new Promise<void>((resolve) => {
        bgImage.onload = () => resolve();
        bgImage.onerror = () => {
          console.warn(`[å¯¼å‡º] èƒŒæ™¯åŠ è½½å¤±è´¥: ${cat}/${file}, å°è¯•ä½¿ç”¨é»˜è®¤èƒŒæ™¯`);
          bgImage.src = 'asset://backgrounds/macOS/sequoia-dark.jpg'; // äºŒæ¬¡å°è¯•é»˜è®¤è·¯å¾„
        };
        bgImage.src = `asset://backgrounds/${cat}/${file}`;
      });

      // 6. è§†é¢‘å¯¼å‡ºå¾ªç¯ (ä½¿ç”¨ VFC åŒæ­¥)
      const vVideo = video as any;
      if (typeof vVideo.requestVideoFrameCallback === 'function') {
        console.log('[useVideoExport] Export via VFC started...');
        await new Promise<void>((resolve, reject) => {
          let vfcId: number | null = null;
          let timeoutId: any = null;
          
          const cleanup = () => {
            if (vfcId !== null) vVideo.cancelVideoFrameCallback(vfcId);
            if (timeoutId) clearTimeout(timeoutId);
            video.removeEventListener('ended', onEnded);
          };
          
          const onFrame = async (_: number, meta: VideoFrameCallbackMetadata) => {
            if (!isExportingRef.current || encoderError) { 
              video.pause();
              cleanup();
              reject(encoderError || new Error('Aborted')); 
              return; 
            }
            
            // æ”¹è¿›ï¼šå¢åŠ ä¸€ä¸ªå°å†—ä½™ï¼Œç¡®ä¿èƒ½æ•æ‰åˆ°æœ€åä¸€ç§’
            if (meta.mediaTime >= durationSeconds - 0.016) { 
              console.log('[useVideoExport] VFC Reached target end time:', meta.mediaTime, '/', durationSeconds);
              video.pause();
              cleanup();
              resolve(); 
              return; 
            }

            if (videoEncoder && videoEncoder.encodeQueueSize > ENCODER_QUEUE_THRESHOLD) {
              video.pause();
              while (videoEncoder.encodeQueueSize > 2) await new Promise(r => setTimeout(r, 10));
              video.play().catch(console.error);
            }

            await renderFrame(meta.mediaTime * 1000);
            const exportCanvas = canvas;
            
            // ğŸ¯ æ ¸å¿ƒä¿®å¤ï¼šä½¿ç”¨è§†é¢‘çœŸå®çš„åª’ä½“æ—¶é—´æˆ³ï¼ˆå¾®ç§’ï¼‰ï¼Œç¡®ä¿å¯¼å‡ºçš„è§†é¢‘é€Ÿåº¦æ°¸è¿œæ­£ç¡®
            const accurateTimestamp = Math.round(meta.mediaTime * 1_000_000);
            const vFrame = new VideoFrame(exportCanvas, { timestamp: accurateTimestamp, alpha: 'discard' });
            
            if (videoEncoder) {
              videoEncoder.encode(vFrame, { keyFrame: encodedCount % 60 === 0 });
            }
            vFrame.close();
            encodedCount++;

            if (performance.now() - lastProgressAt > PROGRESS_THROTTLE_MS) {
              const progressRatio = meta.mediaTime / durationSeconds;
              const displayProgress = isGif ? progressRatio * 0.9 : progressRatio;
              const finalProgress = Math.min(0.95, displayProgress);
              setExportProgress(finalProgress);
              (window as any).ipcRenderer.send('set-progress-bar', finalProgress);
              lastProgressAt = performance.now();
            }
            vfcId = vVideo.requestVideoFrameCallback(onFrame);
          };

          const onEnded = () => { 
            console.log('[useVideoExport] Video native ended. Finalizing frames...');
            cleanup();
            resolve(); 
          };
          video.addEventListener('ended', onEnded);
          
          // å¢åŠ è¶…æ—¶ä¿æŠ¤
          timeoutId = setTimeout(() => {
            console.warn('[useVideoExport] Export timeout reached, resolving current frames.');
            video.pause();
            cleanup();
            resolve();
          }, (durationSeconds + 15) * 1000);

          // ğŸ¯ æ ¸å¿ƒåŒæ­¥æœºåˆ¶ä¿®å¤ï¼š
          // 1. æ˜¾å¼å¯¹é½æ—¶é—´è½´åˆ° 0 
          // 2. åªæœ‰åœ¨æ”¶åˆ°ç¬¬ä¸€ä¸ª requestVideoFrameCallback åæ‰å¼€å§‹è®¡æ•°ï¼Œç¡®ä¿ mediaTime ä¸ frameTimestamp å¯¹é½
          video.currentTime = 0;
          vfcId = vVideo.requestVideoFrameCallback(onFrame);
          
          // ç»™è§£ç å™¨ä¸€ç‚¹ç‚¹å¯åŠ¨æ—¶é—´ï¼ˆ50msï¼‰
          // ğŸ¯ æ¢å¤è‡³ 1.2x ç•¥å¾®æé€Ÿã€‚å¦‚æœè¿˜æ˜¯æ‹…å¿ƒé€Ÿåº¦ï¼Œå»ºè®®ä¿æŒ 1.0 (æœ€ç¨³å¥)
          video.playbackRate = 1.0;
          setTimeout(() => {
            video.play().catch((err) => {
              console.error('[useVideoExport] Video play failed during export:', err);
              cleanup();
              reject(err);
            });
          }, 50);
        });
      } else {
        // Fallback for non-VFC browsers
        console.log('[useVideoExport] VFC not supported, using manual seek fallback...');
        for (let t = 0; t < durationSeconds; t += 1/fps) {
          if (!isExportingRef.current || encoderError) break;
          video.currentTime = t;
          await new Promise(r => {
            const onSd = () => { video.removeEventListener('seeked', onSd); r(null); };
            video.addEventListener('seeked', onSd);
            setTimeout(onSd, 500); // å…œåº•å¤„ç†
          });
          
          await renderFrame(t * 1000);
          const exportCanvas = canvas;
          
          const accurateTimestamp = Math.round(t * 1_000_000);
          const vFrame = new VideoFrame(exportCanvas, { timestamp: accurateTimestamp, alpha: 'discard' });
          if (videoEncoder) {
            videoEncoder.encode(vFrame, { keyFrame: encodedCount % 60 === 0 });
          }
          vFrame.close();
          encodedCount++;
          
          if (performance.now() - lastProgressAt > PROGRESS_THROTTLE_MS) {
            const progressRatio = t / durationSeconds;
            const displayProgress = isGif ? progressRatio * 0.9 : progressRatio;
            setExportProgress(Math.min(0.95, displayProgress));
            lastProgressAt = performance.now();
          }
        }
      }

      // 7. éŸ³é¢‘ç¼–ç å¤„ç†
      if (audioEncoder && decodedAudio && !isGif) {
        console.log('[useVideoExport] Processing audio track...');
        const chans = decodedAudio.numberOfChannels;
        const sr = decodedAudio.sampleRate;
        const maxS = Math.floor(durationSeconds * sr);
        const STEP = 1024;
        for (let i = 0; i < maxS; i += STEP) {
          if (!isExportingRef.current) break;
          const len = Math.min(STEP, maxS - i);
          const data = new Float32Array(len * chans);
          for (let c = 0; c < chans; c++) {
            const src = decodedAudio.getChannelData(c);
            for (let s = 0; s < len; s++) {
               // è¾¹ç•Œæ£€æŸ¥ï¼šå¦‚æœè¶…å‡ºæºéŸ³é¢‘é•¿åº¦ï¼Œå¡«å……é™éŸ³ï¼Œé˜²æ­¢å™ªéŸ³ (crackling)
               const sampleIdx = i + s;
               if (sampleIdx < src.length) {
                 data[s * chans + c] = src[sampleIdx];
               } else {
                 data[s * chans + c] = 0; 
               }
            }
          }
          const ad = new AudioData({ 
            format: 'f32', 
            sampleRate: sr, 
            numberOfFrames: len, 
            numberOfChannels: chans, 
            timestamp: Math.round((i / sr) * 1_000_000), 
            data 
          });
          if (audioEncoder) {
            audioEncoder.encode(ad);
          }
          ad.close();
        }
        if (audioEncoder) {
          await audioEncoder.flush();
          audioEncoder.close();
        }
      }

      if (videoEncoder) {
        await videoEncoder.flush();
        videoEncoder.close();
      }
      console.log('[useVideoExport] VideoEncoder flushed and closed.');
      
      // å…ˆå¼ºåˆ¶æ¸…ç©ºæœ€åçš„ç¼“å†²åŒº
      await flushChunks();
      
      // å…³é”®ä¿®å¤ï¼šmuxer.finalize() ä¼šè§¦å‘å¤§é‡å¼‚æ­¥çš„ onData å›è°ƒ
      console.log('[useVideoExport] Finalizing muxer...');
      muxer.finalize();
      
      // finalize åäº§ç”Ÿçš„å°‘é‡æ•°æ®ä¹Ÿè¦æ¸…ç©º
      await flushChunks();
      
      // ç­‰å¾…æ‰€æœ‰å†™å…¥å®Œæˆ
      await writeChain;
      await new Promise(resolve => setTimeout(resolve, 100));
      await flushChunks(); // ç»ˆæç¡®è®¤
      await writeChain;
      
      console.log(`[useVideoExport] All writes complete. Total chunks: ${chunksReceived}`);
      
      if (chunksReceived === 0 && !isGif) {
        throw new Error('EncoderProducedNoData: The file is empty. Your hardware may not support this resolution or codec.');
      }

      if (streamId) await ipc.invoke('close-export-stream', { streamId });

      if (isGif) {
        setExportProgress(0.99);
        await ipc.invoke('convert-mp4-to-gif', { inputPath: workPath, outputPath: finalPath, fps: 20 });
      }

      setExportProgress(1);
      (window as any).ipcRenderer.send('set-progress-bar', 1);
      (window as any).ipcRenderer.send('show-notification', {
        title: 'å¯¼å‡ºæˆåŠŸ',
        body: `è§†é¢‘å·²ä¿å­˜è‡³: ${finalPath}`,
        silent: false
      });
      setTimeout(() => (window as any).ipcRenderer.send('set-progress-bar', -1), 3000);

      console.log(`[useVideoExport] Export finished in ${((performance.now() - startTime) / 1000).toFixed(1)}s`);
      
      // ğŸ¯ å¯¼å‡ºå®Œæˆåæ¢å¤é¢„è§ˆé…ç½®
      console.log('[useVideoExport] Restoring preview render config...');
      if (canvas) applyRenderConfig(canvas, PREVIEW_CONFIG);
      
      return { success: true, filePath: finalPath };

    } catch (e: any) {
      console.error('[useVideoExport] Export failed:', e);
      // ç¡®ä¿æ¸…ç†èµ„æº
      try {
        if (typeof videoEncoder !== 'undefined' && videoEncoder && videoEncoder.state !== 'closed') {
          await videoEncoder.flush().catch(() => {});
          videoEncoder.close();
        }
        if (typeof audioEncoder !== 'undefined' && audioEncoder && audioEncoder.state !== 'closed') {
          await audioEncoder.flush().catch(() => {});
          audioEncoder.close();
        }
      } catch (cleanupErr) {
        console.error('[useVideoExport] Error during encoder cleanup:', cleanupErr);
      }
      if (streamId) await ipc.invoke('close-export-stream', { streamId, deleteOnClose: true }).catch(() => {});
      
      // ğŸ¯ å¯¼å‡ºå¤±è´¥åä¹Ÿè¦æ¢å¤é¢„è§ˆé…ç½®
      console.log('[useVideoExport] Restoring preview config after error...');
      if (canvas) applyRenderConfig(canvas, PREVIEW_CONFIG);
      
      return { success: false };
    } finally {
      isExportingRef.current = false;
      setIsExporting(false);
      resetCameraCache();
      // ğŸ¯ æ ¸å¿ƒä¿®å¤ï¼šå¯¼å‡ºå½»åº•ç»“æŸï¼ˆæˆåŠŸæˆ–å¤±è´¥ï¼‰åï¼Œç«‹å³æ¢å¤æ’­æ”¾é€Ÿç‡
      if (video) video.playbackRate = 1.0;
    }
  };

  return { handleExport, exportProgress, cancelExport };
}
