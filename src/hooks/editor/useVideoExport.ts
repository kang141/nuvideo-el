import { useState, RefObject, useRef } from 'react';
import { Muxer, StreamTarget } from 'mp4-muxer';
import { QualityConfig } from '../../constants/quality';
import { RenderGraph } from '../../types/render-graph';
import { enableIncrementalMode, resetCameraCache } from '../../core/camera-solver';
import { applyRenderConfig, EXPORT_CONFIG, PREVIEW_CONFIG } from '../../core/render-config';

interface UseVideoExportOptions {
  videoRef: RefObject<HTMLVideoElement>;
  canvasRef: RefObject<HTMLCanvasElement>;
  maxDuration: number;
  exportDuration?: number;
  onSeek: (time: number) => void;
  setIsPlaying: (playing: boolean) => void;
  setIsExporting: (v: boolean) => void;
  renderGraph?: RenderGraph;
  bgCategory?: string;
  bgFile?: string;
  renderFrame: (t: number) => Promise<void>;
}

const ENCODER_QUEUE_THRESHOLD = 12;
const PROGRESS_THROTTLE_MS = 100;

export function useVideoExport({
  videoRef,
  canvasRef,
  maxDuration,
  exportDuration,
  onSeek: _onSeek,
  setIsPlaying,
  setIsExporting,
  renderGraph,
  bgCategory,
  bgFile,
  renderFrame,
}: UseVideoExportOptions) {
  const [exportProgress, setExportProgress] = useState(0);
  const isExportingRef = useRef(false);
  const LAST_DIR_KEY = 'nuvideo_last_export_dir';
  
  type RendererIPC = { invoke: (channel: string, payload?: unknown) => Promise<unknown> };
  const ipc = ((window as unknown) as { ipcRenderer?: RendererIPC }).ipcRenderer!;

  const cancelExport = () => {
    isExportingRef.current = false;
    setIsExporting(false);
    resetCameraCache();
  };

  const handleExport = async (quality?: QualityConfig, targetPath?: string | null): Promise<{ success: boolean; filePath?: string }> => {
    console.log('[useVideoExport] handleExport called', { 
      quality, 
      targetPath, 
      hasRenderGraph: !!renderGraph,
      audioTracks: renderGraph?.audio?.tracks?.length,
      videoSource: renderGraph?.videoSource 
    });
    if (renderGraph) {
      console.log('[useVideoExport] RenderGraph details:', JSON.stringify(renderGraph, (k,v) => k === 'mouse' ? undefined : v, 2));
    }

    if (isExportingRef.current) return { success: false };
    const video = videoRef.current;
    const canvas = canvasRef.current;
    if (!video || !canvas) {
      console.error('[useVideoExport] Required DOM elements missing:', { video: !!video, canvas: !!canvas });
      return { success: false };
    }
    
    
    applyRenderConfig(canvas, EXPORT_CONFIG);
   
    let streamId: string | null = null;
    let isGif = quality?.id === 'gif' || targetPath?.toLowerCase().endsWith('.gif');
    const bitrate = isGif ? 150 * 1024 * 1024 : (quality?.bitrate || 50 * 1024 * 1024);
    const fps = 60;
    const durationSeconds = exportDuration ?? maxDuration;
    // ç¨³å®šæ€§åŠ å›ºï¼šå¼ºåˆ¶åˆ†è¾¨ç‡ä¸ºå¶æ•°ä»¥é€‚é…ç¡¬ä»¶ç¼–ç å™¨
    const width = EXPORT_CONFIG.canvasWidth % 2 === 0 ? EXPORT_CONFIG.canvasWidth : EXPORT_CONFIG.canvasWidth - 1;
    const height = EXPORT_CONFIG.canvasHeight % 2 === 0 ? EXPORT_CONFIG.canvasHeight : EXPORT_CONFIG.canvasHeight - 1;

    // åœ¨ try ä¹‹å‰å£°æ˜ç¼–ç å™¨å˜é‡ï¼Œä»¥ä¾¿åœ¨é”™è¯¯å¤„ç†ä¸­å¯ä»¥è®¿é—®å®ƒä»¬
    let videoEncoder: VideoEncoder | undefined = undefined;
    let audioEncoder: AudioEncoder | null = null;

    try {
      isExportingRef.current = true;
      setIsExporting(true);
      setExportProgress(0);

      // 1. ç¡®å®šä¿å­˜è·¯å¾„
      let finalPath = targetPath;
      if (!finalPath) {
        const ext = isGif ? '.gif' : '.mp4';
        const suggestName = `nuvideo_export_${Date.now()}${ext}`;
        const saveResult = await ipc.invoke('show-save-dialog', { defaultName: suggestName }) as { canceled: boolean; filePath?: string };
        if (saveResult.canceled || !saveResult.filePath) throw new Error('CanceledByUser');
        finalPath = saveResult.filePath;
        const lastSlashIndex = Math.max(finalPath.lastIndexOf('/'), finalPath.lastIndexOf('\\'));
        if (lastSlashIndex > -1) {
          const dir = finalPath.substring(0, lastSlashIndex);
          localStorage.setItem(LAST_DIR_KEY, dir);
        }
      }

      isGif = finalPath!.toLowerCase().endsWith('.gif');
      const workPath = isGif ? finalPath!.replace(/\.(gif|mp4)$/i, '') + `.temp_${Date.now()}.mp4` : finalPath!;

      // 2. é¢„è§£ç å¹¶æ··åˆéŸ³è½¨ï¼ˆGIFæ¨¡å¼è·³è¿‡éŸ³é¢‘å¤„ç†ï¼‰
      let decodedAudio: AudioBuffer | null = null;
      console.log('[useVideoExport] Entering audio processing block...');
      
      if (renderGraph?.audio?.tracks && !isGif) {
        try {
          const audioCtx = new AudioContext({ sampleRate: 48000 });
          const totalSamples = Math.ceil(durationSeconds * 48000);
          const mixedBuffer = audioCtx.createBuffer(2, totalSamples, 48000);
          
          let hasAnyAudio = false;
          const tracks = renderGraph.audio.tracks;
          console.log('[useVideoExport] Audio mixing start. Track count:', tracks.length, 'Duration:', durationSeconds);

          if (tracks.length === 0) {
            console.warn('[useVideoExport] Audio track list is EMPTY.');
          }

          for (const track of tracks) {
            const trackPath = track.path || track.filePath;
            if (!trackPath) {
              console.warn('[useVideoExport] Track missing path:', track);
              continue;
            }

            const targetUrl = trackPath;
            console.log(`[useVideoExport] Processing track: ${track.source}, URL: ${targetUrl}`);
            
            try {
              const resp = await fetch(targetUrl);
              if (!resp.ok) {
                console.error(`[useVideoExport] Fetch failed for ${track.source}: ${resp.status} ${resp.statusText}`);
                continue;
              }
              const arrayBuffer = await resp.arrayBuffer();
              console.log(`[useVideoExport] Decoded raw size: ${arrayBuffer.byteLength} bytes`);
              
              const trackBuffer = await audioCtx.decodeAudioData(arrayBuffer);
              console.log(`[useVideoExport] Track decoded: ${track.source}, Duration: ${trackBuffer.duration.toFixed(2)}s, Channels: ${trackBuffer.numberOfChannels}`);
              
              // æ··åˆåˆ° mixedBuffer
              const startOffset = Math.max(0, Math.floor(((track.startTime || 0) + (renderGraph.audioDelay || 0)) / 1000 * 48000));
              const vol = track.volume ?? 1.0;
              console.log(`[useVideoExport] Mixing ${track.source} at offset: ${startOffset}, volume: ${vol}`);
              
              for (let channel = 0; channel < Math.min(mixedBuffer.numberOfChannels, trackBuffer.numberOfChannels); channel++) {
                const targetData = mixedBuffer.getChannelData(channel);
                const sourceData = trackBuffer.getChannelData(channel);
                const copyLen = Math.min(sourceData.length, targetData.length - startOffset);
                
                // æ·»åŠ è¾¹ç•Œæ£€æŸ¥ï¼Œé˜²æ­¢æ•°ç»„è¶Šç•Œ
                for (let i = 0; i < copyLen; i++) {
                  const targetIdx = startOffset + i;
                  if (targetIdx >= 0 && targetIdx < targetData.length) {
                    targetData[targetIdx] += sourceData[i] * vol;
                  }
                }
              }
              hasAnyAudio = true;
            } catch (trackErr) {
              console.error(`[useVideoExport] Critical error mixing track ${track.source}:`, trackErr);
            }
          }
          
          if (hasAnyAudio) {
            let maxAmp = 0;
            const testData = mixedBuffer.getChannelData(0);
            for (let i = 0; i < Math.min(testData.length, 100000); i += 100) {
              maxAmp = Math.max(maxAmp, Math.abs(testData[i]));
            }
            console.log(`[useVideoExport] Audio mixing complete. Max amplitude sample: ${maxAmp.toFixed(4)}`);
            decodedAudio = mixedBuffer;
          } else {
            console.warn('[useVideoExport] No audio tracks were successfully processed.');
          }
        } catch (e) {
          console.error('[useVideoExport] Audio mixing crash:', e);
        }
      } else {
        console.warn('[useVideoExport] renderGraph.audio or .tracks is missing!');
      }

      // 3. 2026 æè‡´ç²¾ç®€ï¼šä»…ä¿ç•™é€šç”¨ H.264 (AVC)
      const codecCandidates = [
        'avc1.640033', // High Profile (æ¨è)
        'avc1.4d0033', // Main Profile
        'avc1.42E01E', // Baseline Profile (ç»ˆæå…¼å®¹)
      ];
      
      let videoConfig: VideoEncoderConfig | null = null;
      for (const codec of codecCandidates) {
        const testConfig: VideoEncoderConfig = { 
          codec, width, height, bitrate, framerate: fps, 
          hardwareAcceleration: 'no-preference' // è®©ç³»ç»Ÿè‡ªåŠ¨é€‰æ‹©ç¡¬ä»¶æˆ–è½¯ä»¶
        };
        try {
          const support = await VideoEncoder.isConfigSupported(testConfig);
          if (support.supported) {
            videoConfig = testConfig;
            console.log(`[useVideoExport] Selected H.264 codec: ${codec}`);
            break;
          }
        } catch (err) {
          console.warn(`[useVideoExport] AVC ${codec} not supported:`, err);
        }
      }
      
      if (!videoConfig) {
        throw new Error('H.264 (AVC) encoding is not supported on this system.');
      }

      // 4. æ‰“å¼€æµä¸ Muxer
      const openResult = await ipc.invoke('open-export-stream', { targetPath: workPath }) as { success: boolean; streamId?: string; error?: string };
      if (!openResult.success) throw new Error(`StreamOpenFailed: ${openResult.error}`);
      streamId = openResult.streamId || null;

      let writeChain = Promise.resolve();
      let chunksReceived = 0;
      let lastWriteLog = 0;

      const muxerTarget = new StreamTarget({
        onData: (chunk, position) => {
          const chunkLen = chunk.length;
          writeChain = writeChain.then(() => 
            ipc.invoke('write-export-chunk', { streamId, chunk, position })
          ).then(() => { 
            chunksReceived++;
            if (typeof position !== 'number') {
              if (performance.now() - lastWriteLog > 1000) {
                console.log(`[useVideoExport] Writing... Total chunks: ${chunksReceived}, last size: ${chunkLen}`);
                lastWriteLog = performance.now();
              }
            } else {
              console.log(`[useVideoExport] Header backfill at: ${position}, size: ${chunkLen}`);
            }
          }).catch(err => console.error('[useVideoExport] Write Error:', err));
        }
      });

      const muxer = new Muxer({
        target: muxerTarget as any,
        video: { 
          codec: 'avc', 
          width, 
          height, 
          frameRate: fps 
        },
        audio: decodedAudio && !isGif ? { codec: 'aac', sampleRate: 48000, numberOfChannels: 2 } : undefined,
        fastStart: 'in-memory', // æ”¹ä¸ºå†…å­˜ç¼“å†²æ¨¡å¼ï¼Œå¯¹äºçŸ­è§†é¢‘ï¼ˆæ•°åˆ†é’Ÿå†…ï¼‰æ¥è¯´æ›´ç¨³å®šï¼Œé¿å…å›å¡«å¤±è´¥
        firstTimestampBehavior: 'offset',
      });
      console.log('[useVideoExport] Muxer initialized with fastStart: in-memory');

      let encoderError: Error | null = null;
      let encoderOutputCount = 0;
      videoEncoder = new VideoEncoder({
        output: (chunk, meta) => {
          encoderOutputCount++;
          muxer.addVideoChunk(chunk, meta);
        },
        error: (e) => {
          encoderError = e as Error;
          console.error('[useVideoExport] VideoEncoder Error:', e);
        },
      });
      videoEncoder.configure(videoConfig);

      if (decodedAudio && !isGif) {
        audioEncoder = new AudioEncoder({
          output: (chunk, meta) => muxer.addAudioChunk(chunk, meta),
          error: (e) => console.error('[useVideoExport] AudioEncoder error:', e),
        });
        audioEncoder.configure({ codec: 'mp4a.40.2', sampleRate: 48000, numberOfChannels: 2, bitrate: 192_000 });
      }

      // 5. é‡ç½®è§†é¢‘æ’­æ”¾
      video.pause();
      setIsPlaying(false);
      await new Promise(r => {
        const onSd = () => { video.removeEventListener('seeked', onSd); r(null); };
        video.addEventListener('seeked', onSd);
        video.currentTime = 0;
      });

      enableIncrementalMode();
      const startTime = performance.now();
      let lastProgressAt = 0;
      let encodedCount = 0;
      
      // ğŸ¯ å…³é”®ä¿®å¤ï¼šä½¿ç”¨å•è°ƒé€’å¢çš„å¸§è®¡æ•°å™¨ç”Ÿæˆæ—¶é—´æˆ³ï¼Œè€Œä¸æ˜¯ä¾èµ– mediaTime
      // è¿™æ ·å¯ä»¥ç¡®ä¿æ—¶é—´æˆ³æ°¸è¿œæ˜¯é€’å¢çš„ï¼Œé¿å… muxer æŠ¥é”™
      let frameTimestamp = 0;
      const frameDuration = 1_000_000 / fps; // å¾®ç§’ä¸ºå•ä½çš„å¸§é—´éš”

      if (!renderGraph) {
        throw new Error('RenderGraph is required for export');
      }

      console.log('[å¯¼å‡º] æ­£åœ¨åŠ è½½æ¸²æŸ“èµ„æº...');
      
      // åŠ è½½èƒŒæ™¯å›¾ï¼ˆä» Props è·å–ï¼Œå¸¦é»˜è®¤å€¼å…œåº•ï¼‰
      const bgImage = new Image();
      const cat = bgCategory || 'macOS';
      const file = bgFile || 'sequoia-dark.jpg';
      await new Promise<void>((resolve) => {
        bgImage.onload = () => resolve();
        bgImage.onerror = () => {
          console.warn(`[å¯¼å‡º] èƒŒæ™¯åŠ è½½å¤±è´¥: ${cat}/${file}, å°è¯•ä½¿ç”¨é»˜è®¤èƒŒæ™¯`);
          bgImage.src = 'asset://backgrounds/macOS/sequoia-dark.jpg'; // äºŒæ¬¡å°è¯•é»˜è®¤è·¯å¾„
        };
        bgImage.src = `asset://backgrounds/${cat}/${file}`;
      });

      console.log('[å¯¼å‡º] æ¸²æŸ“æµç¨‹å‡†å¤‡å®Œæˆ (ä½¿ç”¨ä¸»ç”»å¸ƒ)');

      // 6. è§†é¢‘å¯¼å‡ºå¾ªç¯ (ä½¿ç”¨ VFC åŒæ­¥)
      const vVideo = video as any;
      if (typeof vVideo.requestVideoFrameCallback === 'function') {
        console.log('[useVideoExport] Export via VFC started...');
        await new Promise<void>((resolve, reject) => {
          let vfcId: number;
          let timeoutId: NodeJS.Timeout;
          
          const cleanup = () => {
            if (vfcId != null) vVideo.cancelVideoFrameCallback(vfcId);
            if (timeoutId) clearTimeout(timeoutId);
            video.removeEventListener('ended', onEnded);
          };
          
          const onFrame = async (_: number, meta: VideoFrameCallbackMetadata) => {
            if (!isExportingRef.current || encoderError) { 
              video.pause();
              cleanup();
              reject(encoderError || new Error('Aborted')); 
              return; 
            }
            
            // æ”¹è¿›ï¼šå¢åŠ ä¸€ä¸ªå°å†—ä½™ï¼Œç¡®ä¿èƒ½æ•æ‰åˆ°æœ€åä¸€ç§’
            if (meta.mediaTime >= durationSeconds - 0.016) { 
              console.log('[useVideoExport] VFC Reached target end time:', meta.mediaTime, '/', durationSeconds);
              video.pause();
              cleanup();
              resolve(); 
              return; 
            }

            if (videoEncoder && videoEncoder.encodeQueueSize > ENCODER_QUEUE_THRESHOLD) {
              video.pause();
              while (videoEncoder.encodeQueueSize > 2) await new Promise(r => setTimeout(r, 10));
              video.play().catch(console.error);
            }

            if (encodedCount % 60 === 0) {
              console.log('[å¯¼å‡º] å‡†å¤‡æ¸²æŸ“å¸§:', { 
                frameIndex: encodedCount, 
                mediaTime: meta.mediaTime.toFixed(3),
                timestampMs: meta.mediaTime * 1000
              });
            }
            
            // ğŸ¯ å…³é”®è¯Šæ–­ï¼šåœ¨æ¸²æŸ“å‰æ£€æŸ¥è§†é¢‘çŠ¶æ€
            if (encodedCount === 0) {
              console.log('[å¯¼å‡º] æ¸²æŸ“å‰è§†é¢‘çŠ¶æ€:', {
                paused: video.paused,
                currentTime: video.currentTime,
                readyState: video.readyState,
                videoWidth: video.videoWidth,
                videoHeight: video.videoHeight
              });
            }
            
            // ğŸ¯ ä½¿ç”¨ä¸»æ¸²æŸ“å™¨ç»˜åˆ¶åˆ°ä¸»ç”»å¸ƒ
            await renderFrame(meta.mediaTime * 1000);
            const exportCanvas = canvas;
            
            // ğŸ¯ è°ƒè¯•ï¼šæ£€æŸ¥ç”»å¸ƒå†…å®¹ï¼ˆæ¯10å¸§æ£€æŸ¥ä¸€æ¬¡ï¼‰
            if (encodedCount % 10 === 0) {
              const ctx = exportCanvas.getContext('2d');
              if (ctx) {
                const imageData = ctx.getImageData(0, 0, Math.min(10, exportCanvas.width), Math.min(10, exportCanvas.height));
                const hasContent = Array.from(imageData.data).some(v => v !== 0);
                const nonZeroCount = Array.from(imageData.data).filter(v => v !== 0).length;
                console.log(`[å¯¼å‡º] ç¬¬${encodedCount}å¸§ç”»å¸ƒæ£€æŸ¥:`, {
                  canvasSize: { width: exportCanvas.width, height: exportCanvas.height },
                  hasContent,
                  nonZeroPixels: nonZeroCount,
                  totalPixels: imageData.data.length,
                  samplePixels: Array.from(imageData.data.slice(0, 16))
                });
              }
            }
            
            const vFrame = new VideoFrame(exportCanvas, { timestamp: frameTimestamp, alpha: 'discard' });
            console.log('[å¯¼å‡º] åˆ›å»ºè§†é¢‘å¸§:', {
              frameIndex: encodedCount,
              timestamp: frameTimestamp,
              mediaTime: meta.mediaTime.toFixed(3),
              frameSize: { width: vFrame.displayWidth, height: vFrame.displayHeight }
            });
            
            if (videoEncoder) {
              videoEncoder.encode(vFrame, { keyFrame: encodedCount % 60 === 0 });
            }
            vFrame.close();
            encodedCount++;
            frameTimestamp += frameDuration; // é€’å¢æ—¶é—´æˆ³

            if (encodedCount % 60 === 0) {
              console.log(`[useVideoExport] Progress - Time: ${meta.mediaTime.toFixed(2)}s, Encoded Frames: ${encodedCount}, Encoder Output: ${encoderOutputCount}`);
            }

            if (performance.now() - lastProgressAt > PROGRESS_THROTTLE_MS) {
              const progressRatio = meta.mediaTime / durationSeconds;
              const displayProgress = isGif ? progressRatio * 0.9 : progressRatio;
              setExportProgress(Math.min(0.95, displayProgress));
              lastProgressAt = performance.now();
            }
            vfcId = vVideo.requestVideoFrameCallback(onFrame);
          };

          const onEnded = () => { 
            console.log('[useVideoExport] Video native ended. Finalizing frames...');
            cleanup();
            resolve(); 
          };
          video.addEventListener('ended', onEnded);
          
          // å¢åŠ è¶…æ—¶ä¿æŠ¤
          timeoutId = setTimeout(() => {
            console.warn('[useVideoExport] Export timeout reached, resolving current frames.');
            video.pause();
            cleanup();
            resolve();
          }, (durationSeconds + 15) * 1000);

          // ğŸ¯ æ ¸å¿ƒåŒæ­¥æœºåˆ¶ä¿®å¤ï¼š
          // 1. æ˜¾å¼å¯¹é½æ—¶é—´è½´åˆ° 0 
          // 2. åªæœ‰åœ¨æ”¶åˆ°ç¬¬ä¸€ä¸ª requestVideoFrameCallback åæ‰å¼€å§‹è®¡æ•°ï¼Œç¡®ä¿ mediaTime ä¸ frameTimestamp å¯¹é½
          video.currentTime = 0;
          vfcId = vVideo.requestVideoFrameCallback(onFrame);
          
          // ç»™è§£ç å™¨ä¸€ç‚¹ç‚¹å¯åŠ¨æ—¶é—´ï¼ˆ50msï¼‰
          setTimeout(() => {
            video.play().catch((err) => {
              console.error('[useVideoExport] Video play failed during export:', err);
              cleanup();
              reject(err);
            });
          }, 50);
        });
      } else {
        // Fallback for non-VFC browsers
        console.log('[useVideoExport] VFC not supported, using manual seek fallback...');
        for (let t = 0; t < durationSeconds; t += 1/fps) {
          if (!isExportingRef.current || encoderError) break;
          video.currentTime = t;
          await new Promise(r => {
            const onSd = () => { video.removeEventListener('seeked', onSd); r(null); };
            video.addEventListener('seeked', onSd);
            setTimeout(onSd, 500); // å…œåº•å¤„ç†
          });
          
          await renderFrame(t * 1000);
          const exportCanvas = canvas;
          
          const vFrame = new VideoFrame(exportCanvas, { timestamp: frameTimestamp, alpha: 'discard' });
          if (videoEncoder) {
            videoEncoder.encode(vFrame, { keyFrame: encodedCount % 60 === 0 });
          }
          vFrame.close();
          encodedCount++;
          frameTimestamp += frameDuration; // é€’å¢æ—¶é—´æˆ³
          
          if (performance.now() - lastProgressAt > PROGRESS_THROTTLE_MS) {
            const progressRatio = t / durationSeconds;
            const displayProgress = isGif ? progressRatio * 0.9 : progressRatio;
            setExportProgress(Math.min(0.95, displayProgress));
            lastProgressAt = performance.now();
          }
        }
      }

      // 7. éŸ³é¢‘ç¼–ç å¤„ç†
      if (audioEncoder && decodedAudio && !isGif) {
        console.log('[useVideoExport] Processing audio track...');
        const chans = decodedAudio.numberOfChannels;
        const sr = decodedAudio.sampleRate;
        const maxS = Math.floor(durationSeconds * sr);
        const STEP = 1024;
        for (let i = 0; i < maxS; i += STEP) {
          if (!isExportingRef.current) break;
          const len = Math.min(STEP, maxS - i);
          const data = new Float32Array(len * chans);
          for (let c = 0; c < chans; c++) {
            const src = decodedAudio.getChannelData(c);
            for (let s = 0; s < len; s++) {
               // è¾¹ç•Œæ£€æŸ¥ï¼šå¦‚æœè¶…å‡ºæºéŸ³é¢‘é•¿åº¦ï¼Œå¡«å……é™éŸ³ï¼Œé˜²æ­¢å™ªéŸ³ (crackling)
               const sampleIdx = i + s;
               if (sampleIdx < src.length) {
                 data[s * chans + c] = src[sampleIdx];
               } else {
                 data[s * chans + c] = 0; 
               }
            }
          }
          const ad = new AudioData({ 
            format: 'f32', 
            sampleRate: sr, 
            numberOfFrames: len, 
            numberOfChannels: chans, 
            timestamp: Math.round((i / sr) * 1_000_000), 
            data 
          });
          if (audioEncoder) {
            audioEncoder.encode(ad);
          }
          ad.close();
        }
        if (audioEncoder) {
          await audioEncoder.flush();
          audioEncoder.close();
        }
      }

      if (videoEncoder) {
        await videoEncoder.flush();
        videoEncoder.close();
      }
      console.log('[useVideoExport] VideoEncoder flushed and closed.');
      
      // å…³é”®ä¿®å¤ï¼šmuxer.finalize() ä¼šè§¦å‘å¤§é‡å¼‚æ­¥çš„ onData å›è°ƒ
      // æˆ‘ä»¬éœ€è¦åœ¨ finalize ä¹‹åå†æ¬¡ç­‰å¾… writeChain ä»¥ç¡®ä¿è¿™äº›å›è°ƒéƒ½å®Œæˆ
      console.log('[useVideoExport] Finalizing muxer (this will trigger header writes)...');
      muxer.finalize();
      
      // ç­‰å¾… finalize è§¦å‘çš„æ‰€æœ‰å†™å…¥å®Œæˆ
      console.log('[useVideoExport] Waiting for all write operations to complete...');
      await writeChain;
      
      // é¢å¤–ç­‰å¾…ä¸€ä¸ª tick ä»¥ç¡®ä¿æ‰€æœ‰ Promise éƒ½å·²è§£å†³
      await new Promise(resolve => setTimeout(resolve, 100));
      await writeChain; // å†æ¬¡ç¡®è®¤
      
      console.log(`[useVideoExport] All writes complete. Total chunks: ${chunksReceived}`);
      
      if (chunksReceived === 0 && !isGif) {
        throw new Error('EncoderProducedNoData: The file is empty. Your hardware may not support this resolution or codec.');
      }

      if (streamId) await ipc.invoke('close-export-stream', { streamId });

      if (isGif) {
        setExportProgress(0.99);
        await ipc.invoke('convert-mp4-to-gif', { inputPath: workPath, outputPath: finalPath, fps: 20 });
      }

      setExportProgress(1);
      console.log(`[useVideoExport] Export finished in ${((performance.now() - startTime) / 1000).toFixed(1)}s`);
      
      // ğŸ¯ å¯¼å‡ºå®Œæˆåæ¢å¤é¢„è§ˆé…ç½®
      console.log('[useVideoExport] Restoring preview render config...');
      if (canvas) applyRenderConfig(canvas, PREVIEW_CONFIG);
      
      return { success: true, filePath: finalPath };

    } catch (e: any) {
      console.error('[useVideoExport] Export failed:', e);
      // ç¡®ä¿æ¸…ç†èµ„æº
      try {
        if (typeof videoEncoder !== 'undefined' && videoEncoder && videoEncoder.state !== 'closed') {
          await videoEncoder.flush().catch(() => {});
          videoEncoder.close();
        }
        if (typeof audioEncoder !== 'undefined' && audioEncoder && audioEncoder.state !== 'closed') {
          await audioEncoder.flush().catch(() => {});
          audioEncoder.close();
        }
      } catch (cleanupErr) {
        console.error('[useVideoExport] Error during encoder cleanup:', cleanupErr);
      }
      if (streamId) await ipc.invoke('close-export-stream', { streamId, deleteOnClose: true }).catch(() => {});
      
      // ğŸ¯ å¯¼å‡ºå¤±è´¥åä¹Ÿè¦æ¢å¤é¢„è§ˆé…ç½®
      console.log('[useVideoExport] Restoring preview config after error...');
      if (canvas) applyRenderConfig(canvas, PREVIEW_CONFIG);
      
      return { success: false };
    } finally {
      isExportingRef.current = false;
      setIsExporting(false);
      resetCameraCache();
    }
  };

  return { handleExport, exportProgress, cancelExport };
}
