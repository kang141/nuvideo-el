import { useEffect, useRef, RefObject, useState } from 'react';
import { EDITOR_CANVAS_SIZE } from '../../constants/editor';
import { RenderGraph } from '../../types';
import { computeCameraState } from '../../core/camera-solver';
import { VideoFrameManager } from '../../core/video-decoder';

interface UseVideoRendererOptions {
  videoRef: RefObject<HTMLVideoElement>;
  canvasRef: RefObject<HTMLCanvasElement>;
  renderGraph: RenderGraph;
  bgCategory: string;
  bgFile: string;
  isExporting?: boolean;
}

export function useVideoRenderer({
  videoRef,
  canvasRef,
  renderGraph,
  bgCategory,
  bgFile,
  isExporting = false,
}: UseVideoRendererOptions) {
  const bgImageRef = useRef<HTMLImageElement | null>(null);
  const macButtonsRef = useRef<HTMLImageElement | null>(null);
  const [isReady, setIsReady] = useState(false);
  const isFirstLoadRef = useRef(true);
  const rafRef = useRef<number>();
  const vfcRef = useRef<number | null>(null);
  const videoSizeRef = useRef({ width: 1920, height: 1080 });
  const layoutRef = useRef({ dx: 0, dy: 0, dw: 0, dh: 0, totalW: 0, totalH: 0, r: 16 });
  const frameManagerRef = useRef<VideoFrameManager | null>(null);
  const webcamFrameManagerRef = useRef<VideoFrameManager | null>(null);
  const webcamVideoRef = useRef<HTMLVideoElement | null>(null);
  // æ ¸å¿ƒä¿®å¤ï¼šè§†é¢‘å¸§ç¼“å­˜å¤‡ä»½ï¼Œå½»åº•æ¶ˆé™¤ seek æ—¶çš„é»‘å±é—ªçƒ
  const mainVideoCacheRef = useRef<HTMLCanvasElement | null>(null); 
  const webcamCacheRef = useRef<HTMLCanvasElement | null>(null);

  // ç¦»å± Canvas ç”¨äºç¼“å­˜é™æ€å±‚ï¼ˆèƒŒæ™¯ + é˜´å½±çª—å£èƒŒæ™¯ï¼‰
  const offscreenRef = useRef<HTMLCanvasElement | null>(null);

  // ç»˜åˆ¶/åˆ·æ–°ç¦»å±é™æ€å±‚
  const updateOffscreen = (vw: number, vh: number) => {
    if (!bgImageRef.current) return;

    if (!offscreenRef.current) {
      offscreenRef.current = document.createElement('canvas');
      offscreenRef.current.width = EDITOR_CANVAS_SIZE.width;
      offscreenRef.current.height = EDITOR_CANVAS_SIZE.height;
    }

    const canvas = offscreenRef.current;
    const oCtx = canvas.getContext('2d');
    if (!oCtx) return;

    const { width: W, height: H } = EDITOR_CANVAS_SIZE;
    oCtx.clearRect(0, 0, W, H);

    // 1. å¯¼å‡ºæ¨¡å¼ä¸‹å¿…é¡»åœ¨ Canvas ä¸­ç»˜åˆ¶èƒŒæ™¯å›¾ï¼Œå¦åˆ™æœ€ç»ˆè§†é¢‘å°†æ˜¯é»‘åº•
    if (isExporting && bgImageRef.current) {
       oCtx.drawImage(bgImageRef.current, 0, 0, W, H);
    }

    // 2. æ ¹æ®è§†é¢‘æ¯”ä¾‹è®¡ç®—å¸ƒå±€å¹¶ç»˜åˆ¶çª—å£é˜´å½± + çª—å£ä¸»ä½“
    const layout = calculateLayout(W, H, vw, vh);
    layoutRef.current = layout; 
    const { dx, dy, totalW, totalH, r } = layout;

    oCtx.save();
    oCtx.shadowColor = 'rgba(0,0,0,0.6)';
    oCtx.shadowBlur = 60;
    oCtx.shadowOffsetY = 30;
    oCtx.fillStyle = '#1e1e1e';
    oCtx.beginPath();
    oCtx.roundRect(dx, dy, totalW, totalH, r);
    oCtx.fill();
    oCtx.restore();

    // 3. é¢„æ¸²æŸ“æµè§ˆå™¨è¾¹æ¡†ä¸æ ‡é¢˜æ  (åŸæœ¬åœ¨ renderFrame ä¸­ï¼Œéå¸¸è€—æ—¶)
    const TB_H = 34;
    const headerGradient = oCtx.createLinearGradient(dx, dy, dx, dy + TB_H);
    headerGradient.addColorStop(0, '#333333');
    headerGradient.addColorStop(1, '#252525');
    oCtx.fillStyle = headerGradient;
    oCtx.beginPath();
    oCtx.roundRect(dx, dy, totalW, TB_H, [r, r, 0, 0]);
    oCtx.fill();

    if (macButtonsRef.current) {
      const btnW = 32;
      const btnH = btnW * (12 / 40);
      oCtx.drawImage(macButtonsRef.current, dx + 12, dy + (TB_H - btnH) / 2, btnW, btnH);
    }

    // ç»˜åˆ¶åœ°å€æ è£…é¥°
    const barW = Math.min(totalW * 0.45, 400); 
    const barH = 20;
    const barX = dx + (totalW - barW) / 2;
    const barY = dy + (TB_H - barH) / 2;
    oCtx.fillStyle = 'rgba(255, 255, 255, 0.05)';
    oCtx.beginPath(); oCtx.roundRect(barX, barY, barW, barH, 4); oCtx.fill();
    oCtx.fillStyle = 'rgba(255, 255, 255, 0.2)';
    oCtx.font = '10px "Inter"'; oCtx.textAlign = 'center';
    oCtx.fillText('ğŸ”’ nuvideo.dev', barX + barW / 2, barY + barH / 2 + 1);
    
    // ç»˜åˆ¶åŠŸèƒ½å›¾æ ‡
    const navX = dx + 64;
    oCtx.strokeStyle = 'rgba(255, 255, 255, 0.2)';
    oCtx.lineWidth = 1.5;
    oCtx.lineCap = 'round';
    oCtx.beginPath(); 
    oCtx.moveTo(navX, dy + TB_H/2 - 4); oCtx.lineTo(navX - 4, dy + TB_H/2); oCtx.lineTo(navX, dy + TB_H/2 + 4); 
    oCtx.moveTo(navX + 16, dy + TB_H/2 - 4); oCtx.lineTo(navX + 20, dy + TB_H/2); oCtx.lineTo(navX + 16, dy + TB_H/2 + 4); 
    oCtx.stroke();
  };

  // åŠ è½½èƒŒæ™¯å›¾ä¸çª—å£è£…é¥°
  useEffect(() => {
    // åŠ è½½æ§åˆ¶æŒ‰é’® SVG
    const btnImg = new Image();
    btnImg.src = '/window-controls.svg';
    btnImg.onload = () => { macButtonsRef.current = btnImg; };

    const img = new Image();
    img.src = `asset://backgrounds/${bgCategory}/${bgFile}`;
    img.onload = () => {
      bgImageRef.current = img;
      updateOffscreen(videoSizeRef.current.width, videoSizeRef.current.height);

      if (isFirstLoadRef.current) {
        setIsReady(true);
        isFirstLoadRef.current = false;
      }

      const video = videoRef.current;
      if (video) requestAnimationFrame(() => void renderFrame(video.currentTime * 1000));
    };
  }, [bgCategory, bgFile, isExporting]); // å¢åŠ  isExporting ä¾èµ–ï¼Œç¡®ä¿å¯¼å‡ºå¼€å§‹æ—¶é‡ç»˜ç¦»å±å±‚

  // å¯åŠ¨ WebCodecs FrameManager
  useEffect(() => {
    const videoSource = renderGraph.videoSource;
    if (!videoSource) return;

    const manager = new VideoFrameManager();
    frameManagerRef.current = manager;

    manager.initialize(videoSource).then(() => {
      // è§£ç å™¨å°±ç»ªåï¼Œæˆ‘ä»¬å¯èƒ½éœ€è¦æ ¹æ®è§†é¢‘å®é™…å°ºå¯¸æ›´æ–°å¸ƒå±€
      // æ³¨æ„ï¼šWebCodecs è§£ç å™¨åŠ è½½åä¼šè‡ªåŠ¨è§£æå°ºå¯¸
      console.log('[useVideoRenderer] WebCodecs Manager initialized');
    });

    return () => {
      manager.destroy();
      frameManagerRef.current = null;
    };
  }, [renderGraph.videoSource]);

  // å¯åŠ¨æ‘„åƒå¤´ WebCodecs FrameManager
  useEffect(() => {
    const webcamSource = renderGraph.webcamSource;
    if (!webcamSource) return;

    const manager = new VideoFrameManager();
    webcamFrameManagerRef.current = manager;

    // æ³¨æ„ï¼šæ‘„åƒå¤´è§†é¢‘é€šå¸¸æ˜¯ 720p ç”šè‡³æ›´ä½ï¼Œè§£ç å‹åŠ›å¾ˆå°
    manager.initialize(webcamSource).then(() => {
      console.log('[useVideoRenderer] Webcam WebCodecs Manager initialized');
    });

    return () => {
      manager.destroy();
      webcamFrameManagerRef.current = null;
    };
  }, [renderGraph.webcamSource]);

  // åˆå§‹åŒ–éšè—çš„ Webcam è§†é¢‘æ’­æ”¾å™¨ (ç›´æ¥ä½¿ç”¨åŸç”Ÿ Video ä»¥æ”¯æŒ WebM)
  useEffect(() => {
    const webcamSource = renderGraph.webcamSource;
    if (!webcamSource) {
      webcamVideoRef.current = null;
      return;
    }

    const video = document.createElement('video');
    video.src = webcamSource;
    video.muted = true;
    video.playsInline = true;
    video.preload = 'auto';
    webcamVideoRef.current = video;

    // çŠ¶æ€åŒæ­¥é€»è¾‘ï¼šè®©æ‘„åƒå¤´æ’­æ”¾å™¨è·Ÿéšä¸»è§†é¢‘çŠ¶æ€
    const mainVideo = videoRef.current;
    
    // çŠ¶æ€åˆ‡æ¢åŒæ­¥ï¼šå¤„ç†æ’­æ”¾ã€æš‚åœã€é€Ÿç‡
    const syncState = () => {
      if (!mainVideo || !video) return;
      video.playbackRate = mainVideo.playbackRate;
      if (mainVideo.paused && !video.paused) video.pause();
      if (!mainVideo.paused && video.paused) video.play().catch(() => {});
    };

    // å¼ºæ ¡å‡†ï¼šä»…åœ¨è¿›åº¦æ‹–åŠ¨æˆ–å¼€å§‹æ’­æ”¾æ—¶å¯¹é½æ—¶é—´è½´
    const hardSync = (tolerance = 0.1) => {
      if (!mainVideo || !video) return;
      const delay = (renderGraph.webcamDelay || 0) / 1000;
      const targetTime = Math.max(0, mainVideo.currentTime - delay);
      
      // å®¹å·®åˆ¤å®šï¼šå¦‚æœåå·®è¿‡å¤§ï¼Œæ‰§è¡Œä¸€æ¬¡ Seekã€‚
      // æ³¨æ„ï¼šSeek æ“ä½œéå¸¸æ˜‚è´µä¸”æ˜¯åŒæ­¥çš„ï¼Œå‡å°‘å®ƒèƒ½æå¤§æå‡æ’­æ”¾å“åº”é€Ÿåº¦ã€‚
      if (Math.abs(video.currentTime - targetTime) > tolerance) {
        video.currentTime = targetTime;
      }
      syncState();
    };

    const onPlay = () => hardSync(0.3);
    const onSeeked = () => hardSync(0.1);
    const onRateChange = () => syncState();
    const onPause = () => syncState();

    if (mainVideo) {
      mainVideo.addEventListener('play', onPlay);
      mainVideo.addEventListener('pause', onPause);
      mainVideo.addEventListener('ratechange', onRateChange);
      mainVideo.addEventListener('seeked', onSeeked);
      // åˆå§‹åŒ–çŠ¶æ€
      hardSync(0.1);
    }

    console.log('[useVideoRenderer] Webcam sync optimized (Low-overhead mode)');

    return () => {
      if (mainVideo) {
        mainVideo.removeEventListener('play', onPlay);
        mainVideo.removeEventListener('pause', onPause);
        mainVideo.removeEventListener('ratechange', onRateChange);
        mainVideo.removeEventListener('seeked', onSeeked);
      }
      video.pause();
      video.src = '';
      video.load();
      webcamVideoRef.current = null;
    };
  }, [renderGraph.webcamSource, videoRef]);

  // ç›‘å¬è§†é¢‘å…ƒæ•°æ®å˜åŒ– (ä¿æŒå…¼å®¹æ€§ï¼Œç”¨äºè·å–å°ºå¯¸å’Œåˆå§‹è§¦å‘)
  useEffect(() => {
    const video = videoRef.current;
    if (!video) return;

    const onMetadata = () => {
      if (video.videoWidth && video.videoHeight) {
        videoSizeRef.current = { width: video.videoWidth, height: video.videoHeight };
        updateOffscreen(video.videoWidth, video.videoHeight);
        requestAnimationFrame(() => void renderFrame(video.currentTime * 1000));
      }
    };

    video.addEventListener('loadedmetadata', onMetadata);
    if (video.readyState >= 1) onMetadata();

    return () => video.removeEventListener('loadedmetadata', onMetadata);
  }, [videoRef, isReady, renderGraph.videoSource]);

  // è¾…åŠ©å‡½æ•°ï¼šè®¡ç®—å¸ƒå±€ (ç®€çº¦ä¸“ä¸šé£ï¼šä¸ç•™è¾¹é»‘æ¡†)
  const calculateLayout = (W: number, H: number, videoW: number, videoH: number) => {
    const TB_H = 34;   // ç¨å¾®å‹ç¼©æ ‡é¢˜æ é«˜åº¦
    const videoAspect = videoW / videoH;
    const padding = 0.85;
    
    let dw = W * padding;
    let dh = dw / videoAspect;
    
    // æ£€æŸ¥æ€»é«˜åº¦æ˜¯å¦è¶…é™
    if (dh + TB_H > H * padding) {
      dh = H * padding - TB_H;
      dw = dh * videoAspect;
    }

    const totalW = dw;
    const totalH = dh + TB_H; 

    return {
      dw, dh, totalW, totalH,
      dx: (W - totalW) / 2,
      dy: (H - totalH) / 2,
      r: 16
    };
  };

  // æ ¸å¿ƒæ¸²æŸ“é€»è¾‘ (å¯é‡å¤è°ƒç”¨)
  const renderFrame = async (timestampMs: number) => {
    const video = videoRef.current;
    const canvas = canvasRef.current;
    if (!video || !canvas || !isReady || !offscreenRef.current) return;

    const ctx = canvas.getContext('2d', { alpha: true });
    if (!ctx) return;
    
    // å…³é”®ä¿®æ­£ï¼šå¿…é¡»æ¯ä¸€å¸§æ‰‹åŠ¨æ¸…ç©ºç”»å¸ƒï¼Œå¦åˆ™ç”±äºå¼€å¯äº† alpha æ¨¡å¼ä¸”èƒŒæ™¯ç”± CSS æä¾›ï¼Œ
    // æ¯ä¸€å¸§çš„ç»˜åˆ¶éƒ½ä¼šåœ¨ä¸Šä¸€å¸§çš„åŸºç¡€ä¸Šå åŠ ï¼Œå¯¼è‡´ç”»é¢â€œç³Šæ‰â€æˆ–å‡ºç°é‡å½±ã€‚
    ctx.clearRect(0, 0, canvas.width, canvas.height);

    const renderGraph = renderGraphRef.current;
    if (!renderGraph) return;

    const camera = computeCameraState(renderGraph, timestampMs);
    const s = camera.scale;

    // --- A. ç»˜åˆ¶é¢„æ¸²æŸ“çš„èƒŒæ™¯/çª—å£å±‚ ---
    ctx.save();
    // å¦‚æœæ­£åœ¨å¯¼å‡ºï¼Œoffscreen å·²ç»åŒ…å«äº†å£çº¸ï¼›å¦‚æœæ˜¯é¢„è§ˆï¼Œoffscreen åªæœ‰çª—å£è£…é¥°
    ctx.drawImage(offscreenRef.current, 0, 0);
    ctx.restore();

    // --- B. å¸ƒå±€å‚æ•° ---
    const TB_H = 34;
    const { dx, dy, dw, dh, totalW, totalH, r } = layoutRef.current;

    // --- C. å‰ªè£å†…å®¹åŒº ---
    ctx.save();
    ctx.beginPath();
    ctx.roundRect(dx, dy, totalW, totalH, r);
    ctx.clip();

    // è§†é¢‘å†…å®¹å±‚
    const videoX = dx;
    const contentY = dy + TB_H;
    ctx.save(); ctx.beginPath(); ctx.rect(videoX, contentY, dw, dh); ctx.clip();
    ctx.translate(videoX + dw / 2, contentY + dh / 2);
    ctx.scale(s, s);
    ctx.translate(-camera.cx * dw, -camera.cy * dh);

    const manager = frameManagerRef.current;
    let frameRendered = false;

    // --- æ ¸å¿ƒæ€§èƒ½å†³ç­–ç­–ç•¥ ---
    // 1. å¦‚æœæ­£åœ¨å¯¼å‡ºï¼Œåˆ™å¿…é¡»ä½¿ç”¨ WebCodecs è§£ç ä»¥ä¿è¯å¸§ç²¾å‡†åº¦å’Œæœ€é«˜ç”»è´¨
    if (isExporting && manager) {
      try {
        const frame = await manager.getFrame(timestampMs);
        if (frame) {
          ctx.drawImage(frame, 0, 0, dw, dh);
          frameRendered = true;
          // æ›´æ–°ç¼“å­˜ä¾›é¢„è§ˆç¬é—´å›é€€
          if (!mainVideoCacheRef.current) mainVideoCacheRef.current = document.createElement('canvas');
          if (mainVideoCacheRef.current.width !== dw) mainVideoCacheRef.current.width = dw;
          if (mainVideoCacheRef.current.height !== dh) mainVideoCacheRef.current.height = dh;
          mainVideoCacheRef.current.getContext('2d')?.drawImage(frame, 0, 0, dw, dh);
        }
      } catch (e) {
        console.warn('[Renderer] WebCodecs export frame failed:', e);
      }
    } 
    // 2. å¦‚æœæ˜¯å®æ—¶é¢„è§ˆï¼Œåˆ™ä¼˜å…ˆä½¿ç”¨åŸç”Ÿ Video æ ‡ç­¾è¿›è¡Œç»˜åˆ¶
    // åŸç”Ÿ Video èµ°ç¡¬ä»¶è§£ç ç®¡çº¿ï¼Œä¸”ç”±æµè§ˆå™¨é«˜åº¦ä¼˜åŒ–ï¼Œä¸ä¼šé˜»å¡ JS ä¸»çº¿ç¨‹
    else if (video.readyState >= 2) {
      ctx.drawImage(video, 0, 0, dw, dh);
      frameRendered = true;
      
      // åœ¨é¢„è§ˆé—´éš”ä¸­å°è¯•é¢„åŠ è½½å¸§ç¼“å­˜
      if (!mainVideoCacheRef.current) mainVideoCacheRef.current = document.createElement('canvas');
      if (mainVideoCacheRef.current.width !== dw) {
         mainVideoCacheRef.current.width = dw; 
         mainVideoCacheRef.current.height = dh;
      }
    }

    // 3. æ ¸å¿ƒè·³è½¬å…œåº•ï¼šå¦‚æœåœ¨ Seek è¿‡ç¨‹ä¸­æˆ–è§£ç æ‰å¸§ï¼Œå›é€€åˆ°æœ€åä¸€å¸§æœ‰æ•ˆç¼“å­˜ï¼Œå½»åº•æ¶ˆé™¤é»‘å±
    if (!frameRendered && mainVideoCacheRef.current) {
      ctx.drawImage(mainVideoCacheRef.current, 0, 0, dw, dh);
    }
    drawSmoothMouse(ctx, camera, dw, dh, renderGraph, timestampMs);
    ctx.restore(); ctx.restore(); ctx.restore();

    // ç»†èŠ‚æè¾¹
    ctx.beginPath(); ctx.roundRect(dx, dy, totalW, totalH, r); ctx.strokeStyle = 'rgba(255,255,255,0.08)'; ctx.lineWidth = 1; ctx.stroke();
    ctx.beginPath(); ctx.moveTo(dx, dy + TB_H); ctx.lineTo(dx + totalW, dy + TB_H); ctx.strokeStyle = 'rgba(255,255,255,0.05)'; ctx.stroke();

    // --- F. æ‘„åƒå¤´ç”»ä¸­ç”» (Webcam PiP) å±‚ ---
    const webcamVideo = webcamVideoRef.current;
    if (webcamVideo && renderGraph.webcamSource && renderGraph.webcam?.isEnabled) {
      const pipSize = renderGraph.webcam?.size ?? 360; 
      const padding = 60;   
      const px = EDITOR_CANVAS_SIZE.width - pipSize/2 - padding;
      const py = EDITOR_CANVAS_SIZE.height - pipSize/2 - padding;

      // è®¡ç®—æ‘„åƒå¤´é‡‡æ ·æ—¶é—´æˆ³ï¼šå‡å»å»¶è¿Ÿé‡ã€‚å¦‚æœç»“æœä¸ºè´Ÿï¼Œè¯´æ˜æ‘„åƒå¤´è¿˜æ²¡å¼€å§‹å½•åˆ¶
      const webcamDelay = renderGraph.webcamDelay || 0;
      const adjWebcamTs = timestampMs - webcamDelay;

      const drawPip = (source: CanvasImageSource) => {
        ctx.save();
        ctx.fillStyle = 'rgba(0,0,0,0.4)';
        ctx.beginPath();
        if (renderGraph.webcam?.shape === 'rect') ctx.roundRect(px - pipSize/2, py - pipSize/2, pipSize, pipSize, 40);
        else ctx.arc(px, py, pipSize/2, 0, Math.PI * 2);
        ctx.fill();

        ctx.save(); ctx.beginPath();
        if (renderGraph.webcam?.shape === 'rect') ctx.roundRect(px - pipSize/2, py - pipSize/2, pipSize, pipSize, 40);
        else ctx.arc(px, py, pipSize/2, 0, Math.PI * 2);
        ctx.clip();

        ctx.translate(px, py); ctx.scale(-1, 1);
        const vw = (source instanceof HTMLVideoElement) ? source.videoWidth : (source as HTMLCanvasElement).width;
        const vh = (source instanceof HTMLVideoElement) ? source.videoHeight : (source as HTMLCanvasElement).height;
        const minSide = Math.min(vw, vh);
        ctx.drawImage(source, (vw - minSide) / 2, (vh - minSide) / 2, minSide, minSide, -pipSize/2, -pipSize/2, pipSize, pipSize);
        ctx.restore();

        ctx.beginPath();
        if (renderGraph.webcam?.shape === 'rect') ctx.roundRect(px - pipSize/2, py - pipSize/2, pipSize, pipSize, 40);
        else ctx.arc(px, py, pipSize/2, 0, Math.PI * 2);
        ctx.strokeStyle = 'rgba(255,255,255,0.15)'; ctx.lineWidth = 3; ctx.stroke();
        ctx.restore();
      };

      if (adjWebcamTs >= 0) {
        const isReady = webcamVideo.readyState >= 2;
        if (isReady && webcamVideo.videoWidth > 0) {
          drawPip(webcamVideo);
        } else if (webcamCacheRef.current && webcamCacheRef.current.width > 0) {
          // å…œåº•ä½¿ç”¨ç¼“å­˜
          drawPip(webcamCacheRef.current);
        }
      }
    }
  };

  // é¢„è§ˆæ¸²æŸ“
  useEffect(() => {
    if (!isReady || isExporting) return;
    const canvas = canvasRef.current;
    if (canvas) { 
      // æ€§èƒ½ä¼˜åŒ–ï¼šåœ¨é¢„è§ˆæ¨¡å¼ä¸‹ä½¿ç”¨ 1.0 DPRã€‚
      // å› ä¸º CSS å·²ç»åº”ç”¨äº† max-width[1024px]ï¼Œ2.5K çš„ç”»å¸ƒä¼šå¯¼è‡´ä¸¥é‡çš„åƒç´ å¡«å……ç‡ç“¶é¢ˆå’Œä¸‹é‡‡æ ·å¼€é”€ã€‚
      const dpr = 1.0;
      canvas.width = EDITOR_CANVAS_SIZE.width * dpr; 
      canvas.height = EDITOR_CANVAS_SIZE.height * dpr;
      const ctx = canvas.getContext('2d', { 
        alpha: true,
        willReadFrequently: false 
      }); 
      if (ctx) {
        ctx.scale(dpr, dpr);
        ctx.imageSmoothingEnabled = true;
        ctx.imageSmoothingQuality = 'high';
      }
    }
    const video = videoRef.current;
    if (!video) return;

    let stopped = false;
    const renderFromCurrentTime = () => { if (!stopped) void renderFrame(video.currentTime * 1000); };
    const onSync = () => requestAnimationFrame(renderFromCurrentTime);
    video.addEventListener('seeked', onSync);
    video.addEventListener('pause', onSync);
    video.addEventListener('loadeddata', onSync);

    const hasVfc = typeof (video as any).requestVideoFrameCallback === 'function';
    if (hasVfc) {
      const onVfc = (_now: number, metadata: VideoFrameCallbackMetadata) => {
        if (!stopped) { void renderFrame(metadata.mediaTime * 1000); vfcRef.current = (video as any).requestVideoFrameCallback(onVfc); }
      };
      vfcRef.current = (video as any).requestVideoFrameCallback(onVfc);
    } else {
      const tick = () => { if (!stopped) { renderFromCurrentTime(); rafRef.current = requestAnimationFrame(tick); } };
      rafRef.current = requestAnimationFrame(tick);
    }
    
    // å…³é”®ä¿®æ­£ï¼šæ— è®ºæ˜¯å¦æœ‰ VFCï¼Œåœ¨è¿›å…¥é¢„è§ˆæ¨¡å¼çš„ä¸€ç¬é—´å¼ºåˆ¶é‡ç»˜å½“å‰æ—¶åˆ»ã€‚
    // è¿™è§£å†³äº†å¯¼å‡ºç»“æŸåï¼Œç”±äºè§†é¢‘å¤„äºæš‚åœçŠ¶æ€ä¸”æ²¡æœ‰æ–°å¸§äº§ç”Ÿï¼Œå¯¼è‡´çš„é¢„è§ˆåŒºå˜é»‘/æŒ‚èµ·çš„é—®é¢˜ã€‚
    renderFromCurrentTime();

    return () => {
      stopped = true;
      video.removeEventListener('seeked', onSync);
      if (rafRef.current) cancelAnimationFrame(rafRef.current);
    };
  }, [isReady, videoRef, canvasRef, isExporting]); // å…³é”®ä¿®å¤ï¼šç§»é™¤äº† renderGraph ä¾èµ–ï¼Œé˜²æ­¢æ‹–æ‹½æ—¶çš„ Effect é‡ç½®é—ªçƒ

  // ä¿æŒ renderGraphRef æœ€æ–°ï¼Œä¾› renderFrame å†…éƒ¨è¯»å–
  const renderGraphRef = useRef(renderGraph);
  useEffect(() => { renderGraphRef.current = renderGraph; }, [renderGraph]);

  // --- å…‰æ ‡è·¯å¾„ ---
  const CURSORS = { macOS: new Path2D('M0,0 L0,18.5 L5,14 L9,22 L11.5,21 L7.5,13.5 L13,13.5 Z') };

  // äºŒåˆ†æŸ¥æ‰¾å½“å‰æ—¶åˆ»å¯¹åº”çš„æœ€åä¸€ä¸ªé¼ æ ‡äº‹ä»¶ç´¢å¼•
  function findLastEventIndex(events: any[], t: number) {
    let low = 0, high = events.length - 1;
    let ans = -1;
    while (low <= high) {
      const mid = (low + high) >> 1;
      if (events[mid].t <= t) {
        ans = mid;
        low = mid + 1;
      } else {
        high = mid - 1;
      }
    }
    return ans;
  }

  function drawSmoothMouse(ctx: CanvasRenderingContext2D, camera: any, dw: number, dh: number, graph: RenderGraph, t: number) {
    const events = graph.mouse;
    if (!events || events.length === 0) return;
    const { style, showRipple, size } = graph.mouseTheme;
    
    const mx = camera.mx * dw;
    const my = camera.my * dh;

    // --- åŠ¨æ€è¿åŠ¨æ®‹å½± ---
    const speedX = camera.mvx * dw * 0.01; 
    const speedY = camera.mvy * dh * 0.01;
    const speed = Math.sqrt(speedX * speedX + speedY * speedY);

    if (speed > 2.0) {
      const trailCount = 3;
      ctx.save();
      for (let i = 1; i <= trailCount; i++) {
        const tax = mx - speedX * i * 3.0;
        const tay = my - speedY * i * 3.0;
        const opacity = 0.25 * (1 - i / (trailCount + 1));
        ctx.beginPath();
        ctx.arc(tax, tay, size * 0.52, 0, Math.PI * 2);
        ctx.fillStyle = `rgba(0, 0, 0, ${opacity})`;
        ctx.fill();
      }
      ctx.restore();
    }
    
    // --- æ€§èƒ½ä¼˜åŒ–æ ¸å¿ƒï¼šå®šä½å½“å‰æ—¶åˆ»çš„äº‹ä»¶ ---
    const lastIdx = findLastEventIndex(events, t);
    if (lastIdx === -1) return;

    let isDown = false;
    // å¾€å‰æœç´¢æ‰¾åˆ°æœ€è¿‘çš„ down/up å†³å®šçŠ¶æ€
    for (let i = lastIdx; i >= 0; i--) {
      if (events[i].type === 'down') { isDown = true; break; }
      if (events[i].type === 'up') { isDown = false; break; }
    }

    // æ¶Ÿæ¼ªæ•ˆæœï¼šä»…å¤„ç†æœ€è¿‘ 600ms çš„äº‹ä»¶
    if (showRipple) {
      ctx.save();
      for (let i = lastIdx; i >= 0; i--) {
        const ev = events[i];
        if (t - ev.t > 600) break; // è¶…å‡ºæ¶Ÿæ¼ªå¯¿å‘½ï¼Œåœæ­¢éå†
        if (ev.type === 'down') {
          const age = t - ev.t;
          const progress = age / 600;
          ctx.beginPath();
          ctx.arc(ev.x * dw, ev.y * dh, progress * size * 1.5, 0, Math.PI * 2);
          ctx.strokeStyle = `rgba(255, 255, 255, ${Math.pow(1 - progress, 2) * 0.4})`;
          ctx.lineWidth = 2 * (1 - progress);
          ctx.stroke();
        }
      }
      ctx.restore();
    }

    ctx.save();
    const visualSize = size * (isDown ? 0.85 : 1.0);
    ctx.translate(mx, my);
    if (style === 'Circle') {
      ctx.beginPath(); ctx.arc(0, 0, visualSize / 2, 0, Math.PI * 2);
      ctx.fillStyle = 'rgba(255,255,255,0.95)';
      ctx.fill();
    } else {
      ctx.scale(visualSize / 22, visualSize / 22);
      ctx.rotate(-Math.PI / 180 * 2);
      ctx.strokeStyle = 'rgba(0,0,0,0.85)';
      ctx.lineWidth = 1.5;
      ctx.stroke(CURSORS.macOS);
      ctx.fillStyle = isDown ? '#e0e0e0' : 'white';
      ctx.fill(CURSORS.macOS);
    }
    ctx.restore();
  }

  return { isReady, renderFrame };
}
